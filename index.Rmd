---
title: "금융데이터 분석을 위한 R을 이용한 개발 입문"
author: "박찬엽"
date: "2017년 7월 20일"
output: 
  slidy_presentation:
    css: kisa.css
    self_contained: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, cache = T)
```

# 강사 소개

kakao : parkets
fb    : [mrchypark](fb.com/mrchypark)

!()[https://raw.githubusercontent.com/mrchypark/kisa_finR/master/profile.png]
  
# 대부분의 에러 문제를 해결할 수 있는 기초 자료형에 대한 이해 {#data-type}

자료형에 대해 알고 있는 것과 자료형을 파악하는 것은 매우 중요합니다. 함수가 입력 데이터로 사용이 가능한 데이터를 입력 데이터로 지정해 주어야 실행이 되기 때문인데요. 많은 분들이 여기에서 문제가 발생합니다. 특히 작업을 진행하면서 기대하지 않은 자료형으로 중간 결과물이 나오는 경우에는 이후에 생기는 문제에 대해서 이해하기 어려울 수 있습니다.  
그렇기 때문에 기본 R에서 제공하는 자료형에 대해서 공부해 두는 것은 대부분의 함수가 사용하는 데이터의 형식을 공부하는 것과 같습니다. 물론 패키지마다 자체 자료형을 정의하기도 합니다. 하지만 지금 기초 자료형을 공부하면서 새로운 자료형을 파악하는 방법을 자연스럽게 배울 수 있을 거라 생각합니다.



자료형을 파악하는 방법은 `class` 함수를 사용하는 것입니다.
```{r}
x <- 1
class(1)
class(x)
class("x")
```
`?class`를 입력해서 `class` 함수에 대해서 파악해 보세요.

위에 `class` 함수의 결과로 나오는 것이 자료형의 종류입니다. `numeric`은 숫자를, `character`는 글자를 뜻합니다. 이제 아래에서 하나하나 확인해 보겠습니다. 기초 자료형에 대해서 [MS의 edX 강의][301], [datacamp][302], [r-tutor][303]의 내용을 참고했습니다.



## 기초 자료형 {#basic-data-type}

### 논리형 logical {#logical}

logical(로지컬) 자료형은 기다 아니다 같이 `True`, `False`를 표현하기 위해 만들어진 자료형입니다. R에서는 각각 두 가지 표현법이 있습니다.
```{r}
TRUE;  class(TRUE)
F;     class(F)
```



언어에 따라 `True`, `False`를 채택하는 경우도 있습니다만 R의 경우 위와 같이 전부 대문자인 글자를 `logical` 자료형으로 인식합니다.

이렇게 `class` 함수를 이용해서 자료형이 무엇인지 파악하는 것도 중요하지만, 조건문 등을 통해서 일을 자동적으로 수행하게 시키기 위해서는 `class` 같이 결과값이 다양한 것 보다는 `logical` 자료형으로 결과가 나오는 것이 앞으로 배우게 될 `if` 문 등에 조건으로 사용하기 좋습니다. 아래와 같은 `is.logical` 함수는 괄호안의 데이터가 `logical` 자료형이 맞는지를 물어보는 함수 입니다. 다른 자료형도 대부분 `is.자료형이름`을 함수로 사용할 수 있습니다.

```{r}
test <- TRUE
is.logical(test)
is.logical(TRUE)
is.logical("test")
```



`R Studio`에서는 함수의 자동완성 기능을 제공합니다. `is.`을 입력해서 다양한 자료형을 확인하는 명령어를 구경해보세요.
<center>![autocomplete](https://raw.githubusercontent.com/mrchypark/data_camp_dabrp/master/images/datatype-autocomplete.png)</center>



### 숫자형 numeric {#numeric}

numeric(뉴메릭) 자료형은 그 영어 뜻이 `숫자의`인 것 같이 숫자를 표현하는 자료형입니다. 물론 복소수 같이 다른 여러 표현들도 사용할 수 있습니다만, R에서 숫자는 보통 `numeric` 자료형으로 처리합니다.
```{r}
2
class(2)
is.numeric(2)
```



`numeric`은 소수점 이하 값을 가지는 숫자도 포함합니다.
```{r}
2.5
class(2.5)
is.numeric(2.5)
```



숫자를 표현하는 자료형으로 `integer`도 있습니다. 영어 뜻 그대로 `정수`를 표현하는 자료형인데요, 소수점이 없는 숫자를 표현할 때 사용합니다. R에서는 `integer`로 바로 인식시키기 위해서 정수인 숫자 뒤에 `L(대문자 엘)`을 붙여서 표현합니다.
```{r}
2L
class(2L)
is.numeric(2L)
is.integer(2L)
```

`integer`는 `numeric`에 비해 차지하는 메모리가 적으며 때문에 연산이 좀 더 빠르다는 장점이 있습니다.



### 글자형 character {#character}

character(캐릭터) 자료형은 그 영어 뜻이 `문자`인 것 같이 글자를 표현하는 자료형입니다. R에서는 변수와 글자를 구분하기 위해서 글자의 앞뒤에 `"`를 붙이는데요. `'`도 같은 역할을 합니다. 그래서 `"`나 `'` 사이에 있는 것은 모두 글자, 즉 character로 인식합니다. 
```{r}
"2"
class("2")
is.numeric("2")
is.character("2")
```



한글도 됩니다.
```{r}
is.character("한글")
```

심지어 `"` 사이에 있는 `'`, `'` 사이에 있는 `"`도 글자로 인식합니다. 이걸 이용해서 글자내에 `"`나 `'`가 들어가야 할 경우, 안에 들어가지 않는 것을 글자로 인식시키기 위한 표시로 사용하기도 합니다.
```{r}
"'"
is.character("'")
```

이렇게 다른 자료형의 기반이 되는 기초 자료형 3개에 대해 알아보았습니다. 이 각각은 지금까지 데이터가 한 개인 경우였습니다. 그렇다면 이 자료형들이 모여 이루는 새로운 자료형에 대해서 알아보겠습니다.



## 벡터 {#vector}

### 하나의 기초 자료형만으로 구성된 1차원 데이터 집합 {#vector-intro}

vector(벡터) 자료형은 가장 간단하게 하나의 자료형에 해당하는 데이터들의 1차원적인 집합입니다.  `vector`를 만드는 가장 간단한 함수는 `c`입니다. `?c`를 실행해서 내용을 한 번 읽어주세요.
```{r}
vec_char <- c("a","b","c")
vec_char
class(vec_char)
is.vector(vec_char); is.character(vec_char)
```



`vec_char`는 `character`이기도 하면서 `vector`입니다. 그럼 이번엔 숫자 벡터를 한번 만들어 보겠습니다.
```{r}
vec_num <- c(1,2,3,4,5)
vec_num
class(vec_num)
is.vector(vec_num)
is.numeric(vec_num)
```



이번엔 `vec_num`이 `numeric`이기도 하면서 `vector`입니다. 마지막으로 논리 벡터를 만들어 볼까요.
```{r}
vec_logi <- c(T,T,T,F,F,T)
vec_logi
class(vec_logi)
is.vector(vec_logi)
is.logical(vec_logi)
```



지금까지 살펴본 바에 따르면 `vector`라는 사실은 `class`로 파악할 수 없고, `is.vector`로 확인할 수 있습니다. 사실 파악할 수 없다보다는 파악할 필요가 없습니다. `vector`는 한 번에 같이 처리할 수 있는 데이터를 묶어둔 것이기 때문에 한 `vector`로 묶인 데이터들은 모두 자료형이 강제로 같게 만들어 집니다. 아래와 같이 다양한 시도를 해서 강제로 자료형이 통일되게 저장되는 것을 확인해 보세요.
```{r}
vec_test1 <- c(1,2,3,"test")
vec_test1
class(vec_test1)
```

이렇게 `vector`는 하나의 기초 자료형만으로 구성된 1차원 데이터 집합인 것을 알게 되었습니다. 그럼 이제 `vector`에서 일부의 데이터만 불러오는 방법을 알아보겠습니다.



### vector에서 일부 데이터 불러오기 {#vector-subset}

데이터를 모아 놓은 것은 좋은 전략이지만 그 중 일부를 자유롭게 사용할 수 있을 때 더욱 빛을 발하는 것 같습니다. vector는 같은 종류의 데이터를 한 줄로 늘어뜨려 놓은 것으로 상상하시면 좋을 것 같은데, 왜냐면 위치로 데이터의 일부를 선택하기 위해서 입니다. 

컴퓨터 언어에서 무엇을 언급하는 방법은 두 가지가 있습니다. 하나는 임의의 이름으로 지정된 주소값 자체를 언급하는 것이고, 다른 하나는 그 주소값에 이름을 부여해서 그 이름을 부르는 것입니다. 정확한 비유는 아닙니다만, `vector`에서 특정 위치에 있는 값을 부르는 것은 위치의 주소값이나 지정해둔 이름으로 값을 부르는 것과 비슷합니다. 값의 순서라고 볼 수 있는 주소값을 `index`라고 합니다.

`R`에서 `index`를 사용하는 방법은 `[ ](대괄호)`를 변수뒤에 붙여서 사용합니다.
```{r}
vec_ind <- c("b","a","ab","b","o","ab")
vec_ind[1]
```



위에서 지정해둔 이름으로 값을 부르는 방법이 있다고 했습니다. 그러면 우선 `vector`의 값에 이름을 부여하는 방법을 살펴보겠습니다. 새롭게 살펴볼 명령어는 `names`입니다. `?names`를 실행해서 살펴보세요.
```{r}
blood_type1 <- c(bob = "A", sam = "B", john="O",jim="AB",tom="A")
blood_type1
names(blood_type1)
```



위의 첫번째 방법은 처음 `vector`를 만들 때 부터 이름을 짓고 시작하는 것입니다. `=`를 기준으로 왼쪽이 이름, 오른쪽이 이름에 해당하는 값입니다. 그럼 다른 방법을 보겠습니다.
```{r}
(blood_type2 <- c("A","B","O","AB","A"))
names(blood_type2)
(blood_type2_name <- c("bob", "sam", "john", "jim", "tom"))
names(blood_type2) <- blood_type2_name
blood_type2
```



`names` 함수가 `vector`의 이름을 보여주는 함수이기도 하면서 값을 지정받을 수 있는 변수의 기능도 합니다. `names(blood_type2)` 전체가 하나의 변수로 동작하는 것이지요. 그래서 처음 선언한 `vector`에 이름이 없는 것을 확인하고 새롭게 이름에 해당하는 변수 `blood_type2_name`을 선언한 후에 `names(blood_type2)`에 선언해줌으로써 이름을 작성했습니다. 두번째 방법을 보면 언제든 새롭게 이름을 지정해 줄 수 있음을 알 수 있습니다.

원래 내용으로 돌아가서, 그럼 이제 이름으로 그 위치에 해당하는 값을 출력해 보겠습니다.
```{}
blood_type1 <- c(bob = "A", sam = "B", john="O",jim="AB",tom="A")
blood_type1[bob]
```

조금 이상합니다. `Error: object 'bob' not found`라고 하면서 동작하질 않네요. `Error` 메세지는 함수가 작동하는데 문제가 있어서 실행이 되질 않았다는 뜻입니다. (참고로 `Warning`은 실행은 됬지만 기대하는 결과가 아닐 수 있으니 확인해보라는 뜻입니다.) `object`는 지금까지 한글로 `변수`라고 불렀습니다. 그럼 변수인 bob이 없다는 에러가 발생한 겁니다. 글자형에서 R에서는 변수와 글자를 구분하기 위해서 글자의 앞뒤에 `"`를 붙인다고 했습니다. 그렇다면 `blood_type1[bob]`에서 `bob`의 앞뒤에 `"`표시를 하지 않았기 때문에 R이 변수로 인식한 듯합니다. 그럼 `"`로 묶어서(앞뒤에 표시해서) 다시 실행해 보겠습니다.
```{r}
blood_type1 <- c(bob = "A", sam = "B", john="O",jim="AB",tom="A")
blood_type1["bob"]
```

이제 원하는 결과가 나왔습니다. 이런 문법에 대해서는 규칙을 정확히 이해하는 것도 중요하지만 계속 `console`에 입력해보면서 테스트를 하는 것이 매우 중요합니다. 그렇게 하면 자주 사용하는 것은 익숙해지고, 기억이 흐릿한 것은 확인해가며 코드를 작성할 수 있게 됩니다.



더 확인해봐야 할 것이 있습니다. 지금까지 한 개만 불러오는 것을 했는데, 여러 개를 동시에 해도 되는지를 확인해 보겠습니다.
```{r}
blood_type1 <- c(bob = "A", sam = "B", john="O",jim="AB",tom="A")
blood_type1[c("bob","john")]
```

여러 개도 가능합니다. 여러 개를 지정하기 위해 `c`함수를 함께 사용한 것에 주목해 주세요. `c`로 이름을 묶어서 사용하지 않으면 어떻게 되는지 확인해 보세요.
```{}
blood_type1 <- c(bob = "A", sam = "B", john="O",jim="AB",tom="A")
blood_type1["bob","john"]
```

`Error in blood_type1["bob", "john"] : incorrect number of dimensions`이라는 `Error`를 보셨으면 맞게 동작하는 것입니다. 메세지를 한번 잘 보겠습니다. `dimension`은 차원이라는 뜻으로 제가 `vector`는 1차원 데이터 집합이라는 표현을 썼었습니다. 그렇다면 차원이 맞지 않게 요청이 되었다는 뜻입니다. R은 `[ ]`안에서 `,(쉼표)`는 차원을 구분하는 것으로 인식합니다. 예를 들어 `[ , , , ]`라고 하면 4차원 데이터를 뜻한다고 할 수 있습니다. 그렇기 때문에 `blood_type1["bob","john"]`은 저희가 의도하지 않는 방식으로 R이 이해한 것입니다. R이 이해하는 대로 해석하면 *첫번째 차원은 이름이 'bob'인 데이터를, 두번째 차원은 이름이 'john'인 데이터를 불러옴*이 됩니다. 하지만 우리는 *첫번째 차원에서 이름이 'bob'인 데이터와 이름이 'john'인 데이터를 불러옴*을 실행하고 싶기 때문에 같은 차원에서 두 개의 이름을 사용했다는 것을 R에게 알려줘야 합니다. 그래서 `c` 함수를 사용해서 이름을 묶어, 여러 데이터를 불러오는 이름을 사용할 때 `vector`를 사용한 것입니다. 이 방법은 차원이 늘어나거나 하더라도 같은 문법을 사용합니다. 그럼 이제 2차원 데이터 집합인 `matrix`를 살펴보겠습니다.



## 메트릭스 {#matrix}

### vector의 2차원 확장 {#matrix-intro}

`matrix`는 간단하게 1차원의 `vector`를 2차원으로 확장한 것입니다. 여기서 2차원이란 1차원 `vector`가 두 줄이 생겼다는 것이 아니라 행과 열로 2차원을 표현하게 됩니다. `matrix`는 많이 보시는 엑셀 시트와 같은 형태를 띕니다. 차원의 의미가 여러 가지가 가능하겠습니다만, 지금의 [차원][304]은 데이터를 표현하는 축의 갯수라고 이해하시면 좋을 것 같습니다.

소개해야 할 자료형 중에 `array`가 있는데 `배열`이라는 뜻입니다. `vector`는 `1차원 array`의 특별한 이름이고, `matrix`는 `2차원 array`의 특별한 이름입니다. 3차원 이상 부터는 전부 `n차원 array`라고 합니다.



그래서 `vector`와 `matrix`, `array`는 앞서 `vector`에서 확인했던 문법적 규칙과 모두 같은 규칙을 따릅니다. 그럼 이제 `matrix`를 한번 만들어 보겠습니다. 
```{r}
matrix(1:6, nrow = 2)
matrix(1:6, ncol = 3)
matrix(1:6, nrow = 2, byrow = TRUE)
```

위에서 `1:6`은 1부터 6까지의 숫자 벡터를 뜻합니다. `c(1,2,3,4,5,6)`과 같습니다. `row`는 행을, `col`은 `column`의 줄임말로 열을 나타내구요. `byrow`옵션이 `TRUE`면 `row`방향으로 먼저 벡터를 나열하라는 뜻입니다.



`matrix`는 행열의 크기를 지정하기 때문에 지정된 크기보다 작은 양의 데이터를 선언할 때 어떻게 동작할 것인지 정해져 있습니다.
```{r}
matrix(1:3, nrow = 2, ncol = 3)
matrix(1:4, nrow = 2, ncol = 3)
```

첫번째 명령에서는 부족한 갯수만큼 있던 것을 다시 사용해서 자동으로 채워줬네요. 두번째 명령에서도 같은 방식으로 동작한 것 같은데 `Warning` 메세지가 나왔습니다. 행의 갯수의 약수거나 배수이지 않다는 것을 알려줌으로써 의도적인 행동인지 확인할 수 있게 도와줍니다. 결과를 확인해보면, 4개까지 사용하고 다시 처음부터 1, 2를 사용하면서 행열의 크기만큼 데이터를 채웠습니다. `Warning`이 나오면 확인해보면 좋겠네요.



행열의 모양을 배우면서 이제 `cbind`와 `rbind`를 확인해 보겠습니다. `cbind`는 **열 방향으로 묶는다.**라는 의미이구요. `rbind`는 **행 방향으로 묶는다**는 뜻입니다. 아래 코드로 어떻게 행열의 모양이 달라지는지 확인해 보세요.

```{r}
cbind(1:3, 1:3)
rbind(1:3, 1:3)
```



```{r}
m <- matrix(1:6, byrow = TRUE, nrow = 2)
m
rbind(m, 7:9)
cbind(m, c(10, 11))
```



`vector`에서 사용한 `names`처럼, 행열에 대응하는 함수가 있습니다. `rownames`, `colnames`가 그것인데요. `?rownames`와 `?colnames`로 자세한 내용을 더 확인해 보시기 바랍니다.
```{r}
m <- matrix(1:6, byrow = TRUE, nrow = 2)
m
rownames(m)
rownames(m) <- c("row1", "row2")
m
```


```{r}
colnames(m)
colnames(m) <- c("col1", "col2", "col3")
m
```



`vector`처럼 처음부터 만들 때 이름을 지정해 줄 수도 있습니다. 
```{r}
m <- matrix(1:6, byrow = TRUE, nrow = 2,
            dimnames = list(c("row1", "row2"),
                            c("col1", "col2", "col3")))
m
```

`matrix`도 `vector`와 같이 한 `matrix`내의 데이터는 모두 같은 자료형이어야 합니다. 이건 자연스럽다고 생각하는 건지 `Warning`도 주지 않으니 조심하셔야 합니다.
```{r}
num <- matrix(1:8, ncol = 2)
char <- matrix(LETTERS[1:6], nrow = 4, ncol = 3)
cbind(num, char)
```



### matrix에서 일부 데이터 불러오기 {#matrix-subset}

`matrix`에서 일부 데이터를 불러오는 방법은 `vector`와 완전히 같습니다. `vector`에서 `[ ]`를 설명하면서 차원에 대해 이야기 했었는데요. `matrix`는 2차원이기 때문에 중간에 쉼표가 들어가야 합니다.

```{r}
m <- matrix(sample(1:15, 12), nrow = 3)
m
m[1,3]
m[3,2]
```



쉼표만 사용하고 어느 하나의 차원을 지정하지 않으면, 모두 불러온 것으로 가정합니다.
```{r}
m[3,]
m[,3]
```

신기하게도, 1차원인 `vector`의 일부 데이터 불러오기의 문법도 사용할 수 있습니다. m[9]가 어느 위치의 값인지 잘 찾아보시기 바랍니다.
```{r}
m[4]
m[9]
```



여전히 `vector`와 같이 어느 한 차원 내에서 여러개를 사용하기 위해서는 `c`와 함께 사용합니다.
```{r}
m[2, c(2, 3)]
m[c(1, 2), c(2, 3)]
m[c(1, 3), c(1, 3, 4)]
```



역시 이름을 사용해서 일부 데이터만 불러오는 것도 가능합니다.
```{r}
rownames(m) <- c("r1", "r2", "r3")
colnames(m) <- c("a", "b", "c", "d")
m
m[2,3] ; m["r2","c"] ; m[2,"c"] ; m[3, c("c", "d")]
```



## 팩터 {#factor}

### 명목형 변수 {#categorical-data}

R에 대해서 이야기 하면서 통계에 대한 이야기가 나오지 않을 수가 없는데요. `factor`는 `categorical data`를 표현하기 위해 만들어진 자료형이기 때문입니다. 통계에서 사용하는 자료형은 [여기][305]를 참고하세요. 가장 대표적인 `categorical data`인 혈액형을 예시로 `factor`를 사용해 보겠습니다.
```{r}
blood <- c("B", "AB", "O", "A", "O", "O", "A", "B")
str(blood)
blood_factor <- factor(blood)
str(blood_factor)
```



자료의 상태를 파악하는 함수로 `str`를 사용했습니다. `str`은 변수의 구조가 어떻게 구성되어 있는지를 보여주는 함수로, 데이터를 파악하는데 좋은 방법입니다. 비슷한 다른 방법들로, `summary`, `head` 등이 있습니다. `?str`, `?summary`, `?head`를 입력해서 내용을 확인해 보세요.



`chr [1:8] "B" "AB" "O" "A" "O" "O" "A" "B"` 에서 `chr`는 `character`의 줄임 표현입니다. 그 다름 `[1:8]`은 데이터가 8개 있다는 뜻입니다. 그 이후에는 8개의 데이터가 모두 출력되었습니다. 

`facter`는 `character`와 다르게 `Levels: A AB B O`라는 줄이 추가 되었습니다. 그리고 데이터를 표현할 때 `"`가 없어졌네요. 우선 그것만으로도 `character`가 아님을 판단할 수 있습니다. `str(blood_factor)`의 결과도 보겠습니다. `Factor w/ 4 levels "A","AB","B","O": 3 2 4 1 4 4 1 3`에서 독특한 부분이 있습니다. 데이터가 숫자로 되어 있네요.

데이터와 비교해 보면 `levels "A", "AB", "B", "0"`에서 3번째는 `"B"`입니다. 첫번째 데이터가 `"B"`인걸 보니 숫자는 `levels`에서 몇 번째 데이터인지를 뜻하는 것 같습니다. 다른 숫자들도 확인해 보세요.



`vector`처럼 변수에 선언할 때 처음부터 `levels`를 지정할 수 도 있습니다. 순서를 지정하는 것도 가능합니다. 처음에 만든 `blood_factor`와 `blood_factor2`가 어떻게 다른지 비교해 보세요.
```{r}
blood_factor2 <- factor(blood,
                        levels = c("O", "A", "B", "AB"))
blood_factor2
str(blood_factor2)
str(blood_factor)

```



`names`처럼 `levels`도 중간에 바꿀 수 있습니다. `labels`라는 것도 있는데, 이것은 데이터의 값을 뜻합니다. 어떻게 달라지는지 확인해 보세요.
```{r}
blood <- c("B", "AB", "O", "A", "O", "O", "A", "B")
blood_factor <- factor(blood)
blood_factor

levels(blood_factor) <- c("BT_A", "BT_AB", "BT_B", "BT_O")
blood_factor
factor(blood, labels = c("BT_A", "BT_AB", "BT_B", "BT_O"))

```



`factor`는 명목형 변수여서 크기를 비교할 수 없습니다.
```{r}
blood <- c("B", "AB", "O", "A", "O", "O", "A", "B")
blood_factor <- factor(blood)
blood_factor[1] < blood_factor[2]
```

하지만 크기를 비교할 수 있는 형태로 선언할 수 도 있습니다. 
```{r}
tshirt <- c("M", "L", "S", "S", "L", "M", "L", "M")
tshirt_factor <- factor(tshirt, ordered = TRUE,
                        levels = c("S", "M", "L"))
tshirt_factor

tshirt_factor[1] < tshirt_factor[2]

```



## 리스트 {#list}

### 다른 종류의 자료형들이 함께 {#list-intro}

지금까지 전부 같은 자료형의 데이터가 모여 있는 형태의 자료형을 알아봤습니다. 같은 자료형으로 구성하는 것은 계산의 효율등 분명한 장점도 있지만, 그것을 사용하는 사람이 이해하기 어렵거나 불편할 때가 있습니다. 특히 다양한 자료형으로 구성된 데이터일 때 하나의 변수로 관리하기 위해서는 `list`를 사용해 합니다. 아래 `c`와 `list`로 만든 데이터를 비교해 보겠습니다.
```{r}
c("Rsome times", 190, 5)
list("Rsome times", 190, 5)
```



`list` 역시 `is.list` 함수가 있네요. `c`로 만들어진 데이터는 자료형을 강제로 전부 `character`로 바꾸었습니다. `list`는 데이터가 주욱 늘어지고, 숫자들은 숫자 데이터로 표현된 것 같습니다. 이 때 처음 보는 것이 있는데요. `[[ ]]`입니다. 이것은 `vector`가 하나의 자료형으로만 이루어져야 하는 점에 착안하여, `vector`를 여러 개 합쳐 `list`를 만듬으로써 문제를 해결했습니다. 그렇기 때문에 일부의 데이터를 불러오는 `[ ]`과 비슷하지만 합쳐져 있는 그 내부의 `vector`를 불러오는 `[[  ]]` 문법이 만들어 지게 되었습니다. `[ ]`과 `[[ ]]`를 실험해 보세요.
```{r}
song <- list("Rsome times", 190, 5)
song[3]
class(song[3])

song[[3]]
class(song[[3]])
```



`list`도 다른 자료형들 처럼 `names`를 사용합니다. 
```{r}
song <- list("Rsome times", 190, 5)
names(song) <- c("title", "duration", "track")
song
```



이번엔 `[[ ]]` 위치에 `$title` 같이 `$ + names`의 문법이 나타났습니다. 이것이 `list`의 이름을 짓는 방법입니다. 이름으로 데이터를 부르는 방법은 더 복잡한 모양의 데이터를 만들고 실습해보기로 하고, `list`가 가진 다른 특성을 확인해 보겠습니다.
```{r}
song <- list(title = "Rsome times",
             duration = 190,
             track = 5)
str(song)

similar_song <- list(title = "R you on time?",
                     duration = 230)

song <- list(title = "Rsome times",
             duration = 190, track = 5,
             similar = similar_song)

str(song)

```



`list` 안에 `list`가 들어가 있네요 `str`로 확인해 보니 `list` 안에 `list`가 `..$`로 들여쓰기 되어 표현되어 있습니다. 데이터 표현도 `List of 2`라고 `str(song)`의 맨 윗줄(`List of 4`)과 같은 모양이 보입니다. 이것처럼 `list`는 대부분의 자료형을 요소로 가질 수 있습니다. 

`list`는 인터넷에서 많이 사용하는 자료형인 `JSON`에 대응됩니다. 과거에는 `XML`도 사용했다고 알고 있는데, 최근에는 많은 곳에서 `JSON`으로 사용하고 있습니다. `JSON`에 대해서는 [이곳][306]의 `예제`를 참고하세요
```{r}
library(N2H4)
url<-"http://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=100&oid=437&aid=0000152054"
tem<-getComment(url)
str(tem)
```

`JSON`을 전문적으로 다루기 위한 [패키지][307]도 있으니 확인해 보세요.



## 데이터프레임 {#data-frame}

### 사람이 이해하기 쉬운 자료형 {#data-frame-intro}

다양한 형태의 자료형을 묶어서 사용하는 `list`를 만들고 보니, 반대로 너무 자유도가 높아서 사용하기 어려운 문제들이 나타났습니다. 그렇다 보니 조금 제약사항을 만들어 보기로 합니다. 그렇게 해서 탄생한게 `data.frame`입니다. 기존에 알고 계시는 엑셀 시트나 설문조사를 정리한 표 같은 걸 생각하시면 도움이 되실 겁니다. `data.frame`은 `list`와 달리 `vector`를 각 열로 유지하여 합치는 방식을 사용했습니다. 그래서 하나의 열 내에서는 데이터가 `vector`와 같이 자료형이 모두 같아야 하고, 하나의 행에서는 자료형이 여러 개가 가능합니다. 
```{r}
name <- c("Anne", "Pete", "Frank", "Julia", "Cath")
age <- c(28, 30, 21, 39, 35)
child <- c(FALSE, TRUE, TRUE, FALSE, TRUE)
df <- data.frame(name, age, child)
df
```



물론 `names`도 사용합니다. `names`는 열의 이름을 뜻합니다. 똑같이 처음부터 지정해 줄수 있구요. 지정하지 않으면 임의로 `data.frame`이 선정해서 가지고 있습니다.
```{r}
names(df)
names(df) <- c("Name", "Age", "Child")
df
(df <- data.frame(Name = name, Age = age, Child = child))
```



`data.frame`은 각 열의 데이터 갯수가 맞지 않으면 만들어 지지 않습니다.
```{}
> data.frame(name[-1], age, child)
## Error in data.frame(name[-1], age, child) : 
##   arguments imply differing number of rows: 4, 5
```

그리고 글자를 모두 `factor`를 기본 값으로 지정합니다. 그래서 `stringsAsFactors` 옵션을 `FALSE`로 해줘야 `charater`로 데이터를 만들 수 있습니다. `stringsAsFactors`는 `options`에서도 지정해서 사용할 수 있습니다.
```{r}
df <- data.frame(name, age, child, 
                 stringsAsFactors = FALSE)
str(df)
```



`list`와 같이 위치값이나 이름으로 데이터의 일부를 불러올 수 있습니다.
```{r}
name <- c("Anne", "Pete", "Frank", "Julia", "Cath")
age <- c(28, 30, 21, 39, 35)
child <- c(FALSE, TRUE, TRUE, FALSE, TRUE)
people <- data.frame(name, age, child, stringsAsFactors = FALSE)
people
people[3,2]
people[3,"age"]
```



```{r}
people
people[3,]
people[,"age"]
people[c(3, 5), c("age", "child")]
```



```{r}
people
people[2]
people$age
people[["age"]]
```



`data.frame`은 데이터를 추가하는 여러 가지 방법을 지원합니다. 이전에 한번씩 본 방식이니 테스트해보세요.
```{r}
height <- c(163, 177, 163, 162, 157)
people$height <- height
people[["height"]] <- height
people

weight <- c(74, 63, 68, 55, 56)
cbind(people, weight)
```



```
> tom <- data.frame("Tom", 37, FALSE, 183)
> rbind(people, tom)
## Error in match.names(clabs, names(xi)) : 
##   names do not match previous names
```

```{r}
tom <- data.frame(name = "Tom", age = 37,
                  child = FALSE, height = 183)
rbind(people, tom)
```



### 순서에 대해 작업하기 {#order-sort}

순서는 `data.frame`뿐만 아니라 다른 자료형에서도 그대로 적용되는 내용입니다. 여기서는 `sort`와 `order`에 대해서 알아보겠습니다.
```{r}
sort(people$age)
ranks <- order(people$age)
ranks
people$age
```



```{r}
ranks <- order(people$age)
ranks

people[ranks, ]

people[order(people$age, decreasing = TRUE), ]

```

`sort`는 순서가 있는 데이터(지금의 예시로는 나이)를 오름차순으로 정렬해줍니다. 글자라면 알파벳순으로 정렬해 줄 것입니다. 한 번 실험해 보세요.  
`order`는 그 위치에 있는 데이터가 전체 데이터 내에서 몇 번째에 위치하는지를 알려줍니다. `sort`가 정렬이 끝난 결과를 보여주는 것이라면 `order`는 그 데이터의 순서값 자체를 보여주는 것이죠. 그렇기 때문에 `order`는 `[ ]`의 행부분 조건과 결합하여 많이 사용됩니다. 



## 날짜 {#date-time}

날짜는 어느 곳에서든 다루기 어려운 데이터입니다. 불규칙적인 윤달이라던지 하는 여러 가지 문제로 실제로 사용할 때 많은 문제가 있는데요, R에서는 여러 형태의 날짜를 표현하는 데이터를 `Date`라는 자료형으로 관리하고 있습니다. 사람들이 관행적으로 사용하는 형태의 `character` 날짜를 `Date`형으로 바꿔보겠습니다.

```{r}
(dates <- c("2016/01/01","2016/02/01","2016/03/01","2016/04/01","2016/05/01","2016/06/01"))
class(dates)
(trans.dates <- as.Date(dates))
class(trans.dates)

```



`Date`형 일때의 장점은 계산이 가능하다는 것입니다.
```{r}
trans.dates[3]-trans.dates[1]
```

다른 모양의 `character`도 되는지 한번 보겠습니다.
```{r}
dates2 <- c("2016-01-01","2016-02-01","2016-03-01","2016-04-01","2016-05-01","2016-06-01")
trans.dates2 <- as.Date(dates2)
trans.dates2
class(trans.dates2)
```



어려운 모양은 인식하지 못합니다. 그래서 일부러 양식을 알려주면 R이 고칠 수 있는데요.
```
> as.Date("2016년 4월 5일")
## Error in charToDate(x) : 문자열이 표준서식을 따르지 않습니다
```
```{r}
as.Date("2016년 4월 5일", format="%Y년 %m월 %d일")
```

양식은 저도 다 외우지 못하고 매번 검색해서 사용합니다.

http://www.stat.berkeley.edu/classes/s133/dates.html

하지만 year의 y(4자 Y, 2자 y), month의 m, day의 d 로 생각하시면 우선 해결되고 나머지는 위에 링크를 참고해 보시면 좋을 것 같습니다.
```{r}
as.Date(34519, origin="1900-01-01")
```



시간은 `POSIXct`와 `POSIXlt` 두 가지로 준비되어 있습니다. 분석에 적용하는데 있어 특별히 구분해서 사용하지 않아서, 하나를 선택하셨다면 일관되게 한 가지만 계속 사용하시면 좋을 것 같습니다.
```{r}
# 시간 자료형
as.POSIXct("2017-04-12 12:00:00")
as.POSIXlt("2017-04-12 12:00:00")

```



날짜와 시간을 다루는 패키지로 유명한 `lubridate`가 있습니다. 아래 여러 코드의 실행결과를 보시면 그 유연한 기능에 감탄하시게 될 겁니다.
```{r}
library(lubridate)
```



```{r}
ymd("2017-05-05")
ymd("170505")
ymd("20170505")
dmy("17-05-15")
ymd("2017년 5월 5일")
dmy("5일5월2017년")
```



```{r}
dates <- c("2017-05-05","170505","20170505","17-05-15","2017년 5월 5일")
ymd(dates)

(data <- ymd("2017-05-05"))
```



```{r}
year(data)
month(data)
month(data, label=T)
```


```{r}
week(data)
yday(data)
mday(data)
wday(data)
wday(data, label=T)

```

# 단순 반복 업무를 위한 for문과 apply류 맛보기 {#for-apply}

## 조건문 {#introduce-if}

### if

`if`는 `if (조건) {조건이 true 이면 실행할 부분}`으로 구성됩니다. 
```{r}
if(TRUE){print(1)}
print(2)
```

조건은 결과가 하나의 `logical` 값으로 나와야 하고 여러 개의 `logical` 값이면 맨 앞의 값만 사용한다는 `warning`을 같이 출력합니다. 
```{r}
if(c(T,F,F,F)){print(1)}
print(2)
```

보통은 아래와 같은 형식으로 사용합니다.
```
x<-1
if ( x > 0 ){
  print(1)
}

```
이제까지 조건이라고 말하는 것이 있었는데, 조건이란 `TRUE`, `FALSE`로 결과가 나오는 표현 전부를 뜻합니다. 제가 `if`문에서 나올 만한 예시를 준비했습니다.
```{r}
x<-c()
if(identical(x,c())){print("x has no data.")}
print("if part done.")

options(stringsAsFactors = F)

y<-c(1,2,3)
z<-c(1,2,3)
if(length(y)==length(z)){
  tem<-data.frame(y,z)
  print(tem)
}
print("if part done.")
```

`identical`은 두 개의 변수를 비교해주고 같으면 `TRUE`, 다르면 `FALSE`를 결과로 주는 함수입니다. 결과를 `logical`로 주는 덕분에 조건문에 사용하기 딱 좋은 함수 입니다. 예를 들어 데이터에 무언가 문제가 생겨서 함수에 들어가지 못하거나 할때 우회하는 조건을 작성하는데 좋습니다.
 저같은 경우는 `N2H4` 패키지를 작성할 때 [getContent][401]에서 사용했습니다. 물론 이상적으로는 정규식과 네이버 뉴스의 root url을 바탕으로 비교하는 식으로 해야 더 정교하겠습니다만, `getUrlListByCategory` 함수에서 생성되는 `link`를 사용하는 형태도 구성되어 있어서 아래와 같이 작성하였습니다.
 
```
...
  if(!identical(url,character(0))){
    if (RCurl::url.exists(url)&
       "error_msg 404"!=(read_html(url)%>%html_nodes("div#main_content div div")%>%html_attr("class"))[1]
        ) {
...
```
조건을 여러개 두고 `and`나 `or`로 묶어서 상황을 파악해야 할 때가 있습니다. 조건이 두 개라고 했을 때 참고할 수 있는 그림이 아래와 같습니다.
![logical](http://r4ds.had.co.nz/diagrams/transform-logical.png)

### else

영어 표현을 보면 생각하기 쉬우시겠지만 `if(조건){조건이 true 이면 실행할 부분}` 이후에 사용해서 조건이 `false`면 실행할 부분을 작성하는데 사용합니다.
`if (조건) {조건이 true 이면 실행할 부분} else {조건이 false 면 실행할 부분} `으로 구성됩니다. 
```{r}
if(TRUE){
  print(1)
} else {
  print(3)
}
print(2)
```

`else`는 앞에 `if`가 조건을 작성했기 때문에 추가적인 조건을 작성하지는 않습니다. 여러 if 조건을 사용하고 그 이후에 else를 사용할 수도 있습니다. 
```{r}
x<-1

if(x<0){
  print(1)
} 
if(x>10) {
  print(3)
} else {
  print(2)
}
print(4)
```

최근의 코드 작성 스타일은 `누가 봐도 읽고 이해하기 쉽게` 이다 보니 고려하면 좋을 것 같습니다. 특히 이 스타일은 자기 자신에게도 적용이 되어서, `나중에 봐도 기억하기 쉽게` 작성하는 것이 좋습니다.

### ifelse

`ifelse`는 앞에 함수와는 다른 결과를 제공해서 사용하는 곳이 다릅니다. 우선 형태는 `ifelse(조건, 조건이 true일때 할 것, 조건이 false일때 할 것)`으로 구성됩니다. 그래서 기존의 데이터를 새로운 기준으로 조정해서 사용할 때 많이 사용합니다.

```{r}
library(readr)
sd<-read_csv("./제3회 Big Data Competition-분석용데이터-05.멤버십여부.txt")
names(sd)[1]<-"고객번호"
sd<-data.frame(sd)

str(sd)
summary(sd)

sd$"최근고객"<-ifelse(sd$"가입년월">mean(sd$"가입년월"),"최근","최근아님")
head(sd)

```

관련해서 [여기][403]를 가보시면 `for`문에 대한 간략한 방법을 질문하시고, 댓글로 여러 답변이 달렸는데, `ifelse`가 가장 좋은 해결책으로 보입니다. 확인해보세요.

### try

`try`는 `error`를 우회하거나 활용하기 위해서 사용하는 함수입니다. 직접 사용할 일은 많지 않지만 함수의 실행에서 에러가 났을 때 (ex> data.frame은 데이터의 길이가 다르면 변수를 만들지 못하고 에러를 출력합니다.) 에러가 난 부분만 기록하고 넘기는 형태로 코드를 작성 할 수 있습니다. 더 섬세하 기능의 `tryCatch` 도 있으니 `?tryCatch`를 확인해주세요.

```
noObj
print(1)
## Error in try(noObj) : object 'noObj' not found
```
```{r}
try(noObj)
print(1)
```

콘솔에서 실행하면 `try(noObj)`에서 에러가 발생합니다. 하지만 멈추는 것이 아니라 다음 코드를 실행하는 것이 그냥 `noObj`를 코드에 작성한 것과 차이점입니다. `try`를 입력해 보시면 `silect` 옵션이 있는데 `TRUE`로 해주면 에러 출력도 하지 않습니다.
```{r}
err<-try(noObj)
err
class(err)
```

위와 같은 식으로 `try(함수)`를 변수에 선언하면 `class(변수)`를 통해 조건문을 활용해서 에러가 발생했을 때를 직접적으로 우회할 수 있습니다.

## 반복문 {#introduce-loop}

### repeat

`repeat`은 가장 단순한 형태의 반복 구분입니다. 그냥 `repeat`만 사용할 수도 있습니다만, 
`repeat(print(1))`을 실행하면 무한히 `1`을 출력하고 멈추지 않습니다. 강제로 멈추는 활동을 해주어야만 멈추니 주의해 주세요. 그래서 `break` 문법이 준비되어 있습니다.

### break

`break`는 말 그대로 멈추라는 명령입니다. `break`는 독특하게 뒤에 `()`를 붙이지 않고 활용하는 함수로 조건문이나 반복문 안에 쓰여서 조건문과 반복문을 멈추는 역할을 합니다.
```{r}
x<-1
repeat(
  if(x>10){
    break
  } else {
  print(x)
  x<-x+1
  }
)
```

### while

사실 `repeat`문은 사용법이 조금 길이서 잘 사용하지 않습니다. 기능적인 대체는 `while`문으로 가능한데, `while`은 `while(조건){조건이 true인 동안 할 것}`으로 구성됩니다.
```{r}
x<-1
while(x<10){
  print(x)
  x<-x+1
}
```

위의 코드가 아까 `repeat`으로 만든 식과 같은 결과를 보여줍니다. 안의 조건이 달라서 이해가 어려우실 수 있어서 `repeat`을 다시 작성해보겠습니다.
```{r}
x<-1
repeat(
  if(x<10){
    print(x)
    x<-x+1
  } else {
    break
  }
)
```

자유도가 높은 `repeat`에 비해서 `while`은 괄고 안의 조건이 `TRUE`일 때 동안만 동작합니다. 하지만 한 방법으로만 고정되어 있어서 오히려 혼란을 막고, 코드가 읽기 좋게 작성할 수 있는 장점이 있습니다.
```{r}
```

### for

`for`는 반복하는 내용을 쉽게 다루기 위해서 준비되어 있습니다. 예를 들어서 위에서 `while`로 작성된 것을 `for`로 다시 작성해 보겠습니다.
```{r}
for(x in 1:9){
  print(x)
}

```

`while`에 비해 훨씬 간결해 졌습니다. 이해하기도 좋구요. `for(반복에 사용할 변수 in 반복에 사용할 변수에 넣을 데이터를 가지는 벡터){반복 실행할 내용 - 반복에 사용할 변수를 활용함}`의 형태로 사용합니다. 말로 풀어 쓰려니 오히려 어려워 보이는 것 같네요. 몇 가지 예시를 더 들어 보겠습니다.

```{r}
data<-head(sd$"고객번호")
for(cNum in data){
  print(sd[sd$"고객번호"==cNum,])
}
```

[N2H4][402]의 사용예시도 복잡하게 무려 `5중 for문(!)`으로 구성되어 있습니다. 중간에 `while`, `try`, `if`도 다 사용되었으니 설명해 드리겠습니다.

### next

에러에 대해 우회하는 것에 대해서 조건문을 주는 방법을 설명드렸었습니다. `next`는 `break`와 비슷하지만 조건문이나 반복문을 멈추는 것이 아니라 다음 번으로 넘기는 역할을 합니다. 예를 들면 아래와 같습니다.

```{r}
data<-head(sd$"고객번호")
for(cNum in data){
  if(sd[sd$"고객번호"==cNum,"최근고객"]=="최근"){next}
  print(sd[sd$"고객번호"==cNum,])
}
```

출력된 내용을 보면 `sd[sd$"고객번호"==cNum,"최근고객"]=="최근"`일 때 다음 줄에 있는 `print`를 하지 않고 `다음(next)`으로 넘어간 것을 확인할 수 있습니다. 이걸 통해서 조건에 따라 그 아래 내용을 실행하지 않고 다음번 반복으로 넘기는 것이 가능합니다.

[N2H4][402]의 사용예시에는 `next`를 사용하지 않고 `while`을 사용했는데, 크롤링 특성상 요청이 일부 실패도 할 수 있기 때문에 추가적인 시도를 하기 위해서 사용했습니다. 데이터를 전부 가져오는 것이 많이 중요하지 않다면 `next`를 사용하는 것이 더 간편하고 빠르게 작성하는 방법이 될 것 같습니다.

지금 예시를 눈으로 보여드리기 위해 `for`문 안을 `print`로 계속 채우고 있는데, `print`의 위치에 수행하고자 하는 함수를 작성하시면 됩니다.

```{r}
X<-as.data.frame(matrix(1:64, ncol=4, dimnames=list(seq(1:16), c("a", "b", "c", "d"))))

X$a[c(1,3,10)]<-0


for (i in 1:nrow(X)){
  if (X$a[i]==0) {
      X$e[i]<-(-999) 
    } else {
      X$e[i]<-X$b[i]/X$c[i]
    }
}
X
```

`ifelse` 함수에서 소개했던 질문쪽의 `for`로 작성된 코드입니다. `for`로 작성하는 것이 사실 생각하기 쉬운 방법이라고 생각합니다. 저는 심지어 처음에는 `for`로 작성하라고 권장합니다. 문제를 직접 겪고, 그 문제를 해결하는 방법을 찾으려할 때 그 방법이 더 몸에 남는 것 같습니다.

아래 `apply`를 하기 전에 `for`와 `ifelse`가 얼마나 다른지 한 번 비교해 보겠습니다.

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)

times<-c(100,1000,10000,30000,50000,100000)
tData<-c()
for(tm in times){

  X<-as.data.frame(matrix(1:tm, ncol=4, dimnames=list(seq(1:(tm/4)), c("a", "b", "c", "d"))))
  
  X$a[c(1,3,10)]<-0
  
  forTime<-system.time(
    for (i in 1:nrow(X)){
      if (X$a[i]==0) {
          X$e[i]<-(-999) 
        } else {
          X$e[i]<-X$b[i]/X$c[i]
        }
    }
  )
  ifelseTime<-system.time(X$e <- ifelse(X$a == 0, -999, X$b/X$c))
  
  forTime<-cbind(data.frame(tm,cate="forTime"),t(as.matrix(forTime)))
  ifelseTime<-cbind(data.frame(tm,cate="ifelseTime"),t(as.matrix(ifelseTime)))
  tData<-rbind(tData,forTime,ifelseTime)
  
}

tData<-tData %>% select(tm:elapsed) %>% gather(tm,cate)
names(tData)<-c("iter","cate","timeName","time")
ggplot(tData,aes(x=iter,y=time,fill=cate,color=cate)) + geom_point(stat="identity")

tm<-1000000
X<-as.data.frame(matrix(1:tm, ncol=4, dimnames=list(seq(1:(tm/4)), c("a", "b", "c", "d"))))
ifelseTime<-system.time(X$e <- ifelse(X$a == 0, -999, X$b/X$c))
ifelseTime

```

이렇게 `for`를 사용하지 않고 다른 방법을 사용하는 것으로 벡터연산이 있습니다. 이름이 중요하진 않으니 R이 감당할 수 있는 수준의 데이터를 `apply`를 통해서 다루는 법을 알아보겠습니다.

## apply류의 함수들 {#introduce-apply}

### apply

`apply` 함수에 대해서 알아보겠습니다. `apply`는 행이나 열 방향의 데이터를 한 번에 계산하는데 사용합니다. 
```{r}
set.seed(1)
( myMat <- matrix(round(rnorm(16,10),2),4,4) )
```

위의 `mymat`에서 각 열의 평균을 구하고 싶으면 이렇게 하면 됩니다.
```{r}
mean(myMat[,1])
mean(myMat[,2])
mean(myMat[,3])
mean(myMat[,4])
```

우리는 `for`를 배웠으니 좀 고쳐 봅시다.
```{r}
for(i in 1:4){
  mean(myMat[,i])
}
```

이게 또 데이터가 따로따로라 `c`도 해줘야 하는 군요.
```{r}
myMean <- c(
  mean(myMat[,1]),
  mean(myMat[,2]),
  mean(myMat[,3]),
  mean(myMat[,4])
)
myMean
```

`for`를 사용하면 이렇게 됩니다.

```{r}
myMean <- c()
for(i in 1:4){
  myMean<-c(myMean,mean(myMat[,i]))
}
myMean
```

여기서 함수화도 많이 진행하는 것 같더군요.
```{r}
myLoop <- function(somemat) {
  myMean <- c()
  for(i in 1:ncol(somemat)){
    myMean<-c(myMean,mean(myMat[,i]))
  }
  return(myMean)
}

myLoop(myMat)
```

근데 이제 열방향 mean 함수를 만드는게 끝났네요. 행방향을 진행하려면 똑같은걸 더 만들어야 합니다. 한 함수에 합쳐서 옵션으로 줘도 좋을 것 같군요. 한번 만들어 보세요.

하지만 `apply`는 이 걸 한줄에 할 수 있게 해줍니다.
```{r}
apply(myMat, 2, mean)
```

위에 결과와 비교해 보세요. 위에서 사용한 `identical` 함수로 두 결과를 비교해 보겠습니다.
```{r}
identical(myLoop(myMat),apply(myMat, 2, mean))
```

`?apply`를 통해 중간의 숫자가 어떤 의미를 가지는지 확인해 보세요. 1은 같은 행끼리의 계산을, 2는 같은 열끼리의 계산을 의미합니다. `apply`는 3가지 옵션을 가지는데, 첫 번째는 데이터, 두 번째는 계산의 방향, 세 번째는 계산에 사용할 함수입니다. 함수부분은 다양한 함수를 사용할 수 있습니다.
```{r}
apply(myMat,2,class)
apply(myMat,2,sum) 
apply(myMat,2,quantile) 
```

자주 사용하는 평균이나 합 같은 경우는 함수로도 구현되어 있습니다. `rowMeans`, `colMeans`, `rowSums`, `colSums`가 그것 입니다. 각각 `apply`로 어떻게 하면 되는지 생각해 보세요.

`apply`에 적용하는 함수 안에 데이터만 들어가는 함수 이외에 다른 옵션을 지정해야 할 수 있습니다. `apply`는 `,`를 이용해서 다음 옵션으로 사용하는 함수 안의 옵션을 작성할 수 있습니다.
```{r}
myMat[1,4]<-NA
apply(myMat,2,sum)
apply(myMat,2,sum, na.rm = TRUE)
```

`apply`에서 계산에 사용할 함수는 사용자가 만들어서 진행할 수도 있고, 임시로 만들 수도 있습니다.
```{r}
naSum <- function(x){
  return(sum(x,na.rm = TRUE))
}

apply(myMat,2,naSum)
apply(myMat,2,function(x) sum(x,na.rm = TRUE))

```

만들어야 할 함수가 복잡하지 않으면 저는 임시로 작성하는 방법을 사용하는 편입니다.

### apply-family {#applys}

`apply`는 `lapply`, `tapply`, `sapply`, `mapply` 등의 `apply-family`를 가지고 있습니다. 

우선 `lapply`부터 살펴보겠습니다. 앞에 `l`이 붙으면서 `list` 자료형에 대해 `apply`의 역할을 수행하는 함수라는 의미가 붙었습니다. 결과도 `list`로 나옵니다.
```{r}
(listData <- list(a = 1, b = 1:3, c = 10:100) )
lapply(listData, length) 
lapply(listData, sum)
```

`list` 자료형은 사용하시면서 느끼시겠지만 다른 곳에 사용하기 불편한 점이 있습니다. 그래서 다시 `list`를 푸는 방법으로 `unlist`를 사용하는데요. `?unlist`를 입력해서 내용을 확인해보세요.

```{r}
(listData <- list(a = 1, b = 1:3, c = 10:100) )
unlist(lapply(listData, length))
unlist(lapply(listData, sum))
```

그런데 입력을 `list`로 받는 것은 어쩔수 없다고 쳐도, 결과물은 위처럼 `vector`로 받는 것이 편한 경우가 많습니다. `unlist(lapply(데이터,함수))`는 `sapply`와 같은 동작을 합니다.
```{r}
(listData <- list(a = 1, b = 1:3, c = 10:100) )
sapply(listData, length)
sapply(listData, sum)

```

이외에도 `list안에 list`까지 계산하는 `rapply`, 지정한 이름으로 실행할 수 있는 `tapply` 등이 있습니다만, 거의 `apply`나 `sapply`만 사용한 것 같습니다.

더 궁금하신 사항은 [여기][404]를 참고해 주세요.

# tidy data 개념과 dplyr+tidyr로 데이터 다루기 {#tidyr}

 데이터 분석을 어렵게 하는 여러 이유들이 있습니다. 이게 개발 커뮤니티에서 말하는 [기술 부채][601]와 같은 개념이지 않나 생각이 들어 데이터 부채라는 표현을 사용해 보았습니다. 여러 데이터 관련 구루들이 강조하는 바, 데이터 분석의 대부분의 시간(약 80%)은 데이터 수집과 전처리, 정제에 사용됩니다. 계륵 같은 일이죠. [garbage in, garbage out; GIGO][602] 이니까요. 데이터가 많지 않았던 시대에는 처리에 시간을 쏟는 것이 너무 당연한 일이었습니다. 하지만 데이터 생성을 설계할 수 있는 입장(서비스 제공자, 마케터 등)에서는 저 시간은 명확하게 비용, 즉 데이터 부채가 되는 것입니다.

 이 데이터 부채가 쌓이는 것을 처음부터 막을 수 있도록 데이터가 저장되는 방식에 대해 제안된 개념이 있는데 그것이 [tidy data][603]입니다. tidy data란 개념은 [Hadley Wickham][604]이 제안했습니다.

## 단정한 데이터 {#tidy-data}

 이것에 대해 본인이 직접 [장문의 설명][605]을 한 것도 있고 R 한글 형태소 분석 패키지인 konlp을 만드신 고감자님의 [한글 설명][606], MS의 데이터 과학자이시자 헬로우 데이터과학의 저자이신 김진영님의 [도서 블로그][607]에도 너무 잘 설명되어 있습니다. 추가로 더 내용이 필요하시면 참고하시기 바랍니다.
 먼저 tidy data의 개념이 필요한 이유는 컴퓨터에게 분석을 시켜야(!) 하기 때문입니다. 그래서 tidy data는 사람이 눈으로 이해하기에는 적절하지 않을 수 있습니다. 이 곳이 진입장벽이 되기도 하는데, 현재 사용하고 있는 엑셀을 바로 R에 넣고 사용하고 싶은데, 잘 안되는 경우가 많습니다. 그것은 엑셀 파일내 데이터를 사람이 "보기 좋게" 위치했기 때문입니다. 
그럼 이제  tidy data의 세 가지 조건을 원문(1)과 고감자님 번역(2), 김진영님 번역(3)순으로 살펴보겠습니다.

1.1 Each variable forms a column.  
1.2 각 변수는 개별의 열(column)으로 존재한다.  
1.3 각 열에는 개별 속성이 들어간다. 

2.1 Each observation forms a row.  
2.2 각 관측치는 행(row)를 구성한다.  
2.3 각 행에는 개별 관찰 항목이 들어간다.

3.1 Each type of observational unit forms a table.  
3.2 각 테이블은 단 하나의 관측기준에 의해서 조직된 데이터를 저장한다.  
3.3 각 테이블에는 단일 유형의 데이터가 들어간다.

![tidydata](http://r4ds.had.co.nz/images/tidy-1.png)

1번을 보기 전에 2번을 먼저 보겠습니다.(2>1>3 순으로 쉬워요.) 2번은 단순합니다. 하나의 데이터가 한 줄(행)을 구성해야 한다는 것입니다. 설문지를 예로 들면 한명의 설문 결과가 한 줄로써 저장되는 것이죠. Each observation(개별 관찰)은 하나의 관찰 결과(=설문지 하나)를 뜻합니다. `sql`이나 `data.frame`에서 보셨듯 `row`는 조건으로 데이터를 `filter`할 수 있는 공간입니다. 그렇기 때문에 각 `row`는 개별 데이터를 의미합니다.

1번은 2번과 같은 하나가 들어가는 개념이긴 합니다만 하나의 variable, 변수, 개별 속성이라는 점이 조금 어렵습니다. 설문지 예시는 쉽습니다. 하나의 문항이라고 이해하면 되거든요. 그런데 variable이라는게 뭔지를 아는 것이 저는 조금 어려웠습니다. 찾아보니 영어상은 변수, 변할수 있는 수(여기서는 수보다는 값이라고 이해하시면 좋습니다.)인데 그 변수를 대표하는 이름이 컬럼명이라고 생각하면 좋더군요. 

그런데 컬럼이 변수에 속하는 값으로 구성되는 경우가 있습니다. 예를들어 날짜가 컬럼명에 들어간 경우죠. 이렇게 생긴 데이터를 [wide form][608]이라고 합니다. 날짜는 변수에 들어갈 값이기 때문에 컬럼명을 날짜(date, datetime, when 등)로 정하고 컬럼에 속하는 cell에 날짜가 들어가는 형태로 구성하는 것이 tidy data의 조건을 충족하는 셈이 됩니다.

3번은 단일 테이블이 어떻게 구성되어야 하는지를 알려주는 조건입니다. 김진영님의 번역이 좀 이해하기 쉬운 것 같습니다. 테이블 하나에 하나의 데이터가 들어가야 된다는 뜻인데요, 아래 dplyr과 tidyr을 배우면서 예시들도 같이 보겠습니다.

## dplyr + tidyr

`dplyr`은 `plyr` 패키지의 `data.frame` 전용이라는 의미를 가지고 있습니다. `plyr`은 데이터의 [분해 - 적용 - 재조립 전략][610]을 실행할 수 있는 [패키지][609]입니다. 이 전략을 `data.frame` 형태에서 실행하기 위해서 여러 명령어들을 제공합니다. `잘 정돈된 데이터 프레임`은 [분해 - 적용 - 재조립 전략][610]을 실행하기 쉬우며 데이터를 잘 정돈하기 위해 `tidyr` 패키지를 함께 사용할 수 있습니다. 최근 `ggplot2`, `dplyr`, `tidyr` 등 tidy data의 개념과 같은 맥락에 있는 패키지들이 하나로 모여 `tidyverse` 패키지가 되었습니다.

```{r}
library(tidyverse)
```

### pipe 연산자 %>% {#pipe-operator}

`%>%`는 함수의 사용 방향을 바꿔서 읽고 이해하기 쉽게 만든 연산자입니다.
```
g(f(y)) == y %>% f() %>% g()
```

이렇게 사용하고 `tidyverse` 패키지 전반적으로 사용하는 방식입니다.   
`.`으로 앞의 변수의 위치를 지정할 수도 있고, 괄호 안에 작성할 것이 없을 때는 괄호를 생략할 수도 있습니다.
```
g(f(x,y,z)) == y %>% f(x, . , z) %>% g
```


### dplyr 명령어 소개 {#dplyr-functions}

`dplyr`에는 행에 조건을 줘서 부분을 불러오는 `filter()`, 필요한 컬럼만 선택하는 `select()`, 새로운 컬럼을 계산하는 `mutate()`, 조건에 따라 재정렬 할 수 있는 `arrange()`, `group_by()`와 함께 써서 요약값을 계산할 수 있는 `summarise()`가 있습니다. `group_by()`는 `mutate()`, `filter()`와도 사용할 수 있습니다.

```{r}
if(!require(nycflights13)) install.packages("nycflights13")
library(nycflights13)
flights
```

첫번째 `filter()`를 사용해 보겠습니다.
```{r}
filter(flights, month == 1, day == 1)
jan1 <- filter(flights, month == 1, day == 1)
(dec25 <- filter(flights, month == 12, day == 25))
```


```{r}
filter(flights, month == 11 | month == 12)
nov_dec <- filter(flights, month %in% c(11, 12))
nov_dec
filter(flights, !(arr_delay > 120 | dep_delay > 120))
filter(flights, arr_delay <= 120, dep_delay <= 120)
```

`arrange()`는 조건을 바탕으로 정렬을 다시 해줍니다.
```{r}
arrange(flights, year, month, day)
arrange(flights, desc(arr_delay))
df <- tibble(x = c(5, 2, NA))
arrange(df, x)
arrange(df, desc(x))
```

`select()`는 컬럼을 선택하는 함수라고 했습니다.
```{r}
select(flights, year, month, day)
select(flights, year:day)
select(flights, -(year:day))
```

`select`와 함께 사용하는 함수로 `starts_with("abc")`, `ends_with("xyz")`, `contains("ijk")`, `matches("(.)\\1")`, `num_range("x", 1:3)`등을 들 수 있습니다. `?select`를 실행해서 자세한 사항을 확인해보세요.

`rename()`은 컬럼의 이름을 바꾸는 함수고, `everything()`은 선택한 것 이외에 전부를 뜻합니다.
```{r}
rename(flights, tail_num = tailnum)
select(flights, time_hour, air_time, everything())
```

`mutate()`는 새로운 변수 계산을 위해서 필요합니다.
```{r}
flights_sml <- select(flights, 
  year:day, 
  ends_with("delay"), 
  distance, 
  air_time
)
mutate(flights_sml,
  gain = arr_delay - dep_delay,
  speed = distance / air_time * 60
)
mutate(flights_sml,
  gain = arr_delay - dep_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
)
transmute(flights,
  gain = arr_delay - dep_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
)
```

특별히 `mutate()`와 함께 사용하는 함수중에 `lag()`와 `lead()`를 소개할까 합니다.
```{r}
(x <- 1:10)
lag(x)
lead(x)
```

`mutate()`가 각 행에 대한 계산 결과를 하나의 컬럼으로 만들어 주는 것이라면 `summarise()`는 일정 조건(대부분 `group_by()`를 이용한 그룹화)에 해당하는 계산을 수행해줍니다.
```{r}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))

by_day <- group_by(flights, year, month, day)
summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))

daily <- group_by(flights, year, month, day)
(per_day   <- summarise(daily, flights = n()))
(per_month <- summarise(per_day, flights = sum(flights)))
(per_year  <- summarise(per_month, flights = sum(flights)))

daily %>% 
  ungroup() %>% 
  summarise(flights = n())

```

`group_by()`를 `mutate()`, `filter()`와도 사용할 수 있다고 했습니다.
```{r}
flights_sml %>% 
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)

popular_dests <- flights %>% 
  group_by(dest) %>% 
  filter(n() > 365)
popular_dests

popular_dests %>% 
  filter(arr_delay > 0) %>% 
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>% 
  select(year:day, dest, arr_delay, prop_delay)
```

### tidyr 명령어 소개 {#tidyr-functions}

`tidyr`에는 `long form`을 `wide form`으로 바꿔주는 `spread()`, 반대로 `wide form`을 `long form`으로 바꿔주는 `gather()`, 여러 의미를 지닌 데이터를 특정 글자를 기준으로 분리해 주는 `seperate()`, 그 반대로 합치는 `unite()`, 데이터를 분리하는 폼을 지정해 줄 수 있는 `extract()`가 있습니다.

우선 내장된 데이터를 소개하겠습니다.
```{r}
table1
table2
table3
table4a
table4b
```

이제 많이 사용하게 될 `gather()` 함수를 보겠습니다.
```{r}
table4a
table4a %>% 
  gather(`1999`, `2000`, key = "year", value = "cases")
```
![gather](http://r4ds.had.co.nz/images/tidy-9.png)

이번엔 반대과정인 `spread()`를 보겠습니다.
```{r}
table2
spread(table2, key = type, value = count)
```
![spread](http://r4ds.had.co.nz/images/tidy-8.png)

한 셀에 여러 값이 있어서 나눠야 할 때는 `seperate()`를 사용합니다. `sep`옵션을 주지 않아도, 간단한 것은 알아서 나눠줍니다.
```{r}
table3
table3 %>% 
  separate(rate, into = c("cases", "population"))

table3 %>% 
  separate(rate, into = c("cases", "population"), convert = TRUE)

table3 %>% 
  separate(year, into = c("century", "year"), sep = 2)
```

`unite()`는 합쳐주는 `seperate()`와는 반대의 기능을 가진 함수입니다.
```{r}
table5 %>% 
  unite(new, century, year)

table5 %>% 
  unite(new, century, year, sep = "")
```

### dplyr과 join {#dplyr-join}

`dplyr`에는 `join()` 기능도 있습니다. 데이터를 먼저 소개하겠습니다.
```{r}
airlines
airports
planes
weather
```

`%>%`와 `join()` 명령어로 쉽게 데이터를 합칠 수 있습니다.
```{r}
flights2 <- flights %>% 
  select(year:day, hour, origin, dest, tailnum, carrier)
flights2
flights2 %>%
  select(-origin, -dest) %>% 
  left_join(airlines, by = "carrier")

flights2 %>%
  select(-origin, -dest) %>% 
  mutate(name = airlines$name[match(carrier, airlines$carrier)])
```

`key`를 선정해주는 것과 아닌 것이 어떻게 다른지 봐주세요.
```{r}
flights2 %>% 
  left_join(weather)

flights2 %>% 
  left_join(planes, by = "tailnum")
```

왼쪽 테이블과 오른쪽 테이블의 어떤 `key`를 기준으로 `join()`할 건지 지정할 수 있습니다. 
```{r}
flights2 %>% 
  left_join(airports, c("dest" = "faa"))

flights2 %>% 
  left_join(airports, c("origin" = "faa"))
```

`join()` 함수는 `base::merge()`, `SQL`과 비교할 수 있습니다.
```
inner_join(x, y) == merge(x, y)
left_join(x, y)  == merge(x, y, all.x = TRUE)
right_join(x, y) == merge(x, y, all.y = TRUE),
full_join(x, y)  == merge(x, y, all.x = TRUE, all.y = TRUE)

inner_join(x, y, by = "z") == SELECT * FROM x INNER JOIN y ON x.z = y.z
left_join(x, y, by = "z")  == SELECT * FROM x LEFT OUTER JOIN y ON x.z = y.z
right_join(x, y, by = "z") == SELECT * FROM x RIGHT OUTER JOIN y ON x.z = y.z
full_join(x, y, by = "z")  == SELECT * FROM x FULL OUTER JOIN y ON x.z = y.z
```

## data.table

`data.table`은 지금까지와는 조금 다른 문법을 가지고 있습니다. `fread`와 `fwrite`이라는 강력한 `IO`함수를 가지고 있으며 `data.table`은 패키지 명이면서 `data.frame`과 호환되는 자료형이기도 합니다. 자세한 내용은 [여기][612]를 참고해 주세요.
```{r}
library(data.table)
url<-"https://github.com/arunsrinivasan/flights/wiki/NYCflights14/flights14.csv"
dir.create("./data",showWarnings = F)
download.file(url,destfile = "./data/flights14.csv")
system.time(flights <- read.csv("./data/flights14.csv"))
system.time(flights <- fread("./data/flights14.csv"))
flights
dim(flights)

ans <- flights[origin == "JFK" & month == 6L]
head(ans)

ans <- flights[1:2]
ans

ans <- flights[order(origin, -dest)]
head(ans)

ans <- flights[, arr_delay]
head(ans)

ans <- flights[, .(arr_delay, dep_delay)]
head(ans)

ans <- flights[, .(delay_arr = arr_delay, delay_dep = dep_delay)]
head(ans)

flights[, sum((arr_delay + dep_delay) < 0)]

flights[origin == "JFK" & month == 6L,
	       .(m_arr = mean(arr_delay), m_dep = mean(dep_delay))]

flights[origin == "JFK" & month == 6L, length(dest)]

flights[, .(.N), by = .(origin)]

flights[carrier == "AA", .N, by = origin]

flights[carrier == "AA", .N, by = .(origin,dest)]

flights[carrier == "AA", .N, by = .(origin, dest)][order(origin, -dest)][1:10,]
```

# 주식 데이터를 tidy 개념으로 tidyquant {#tidyquant}

`tidyquant`는 `quantmod` 등 주식 분석을 주 목적으로 하는 중요 함수를 제공하는 중요한 패키지입니다. `tidy data` 개념을 활용한 데이터 핸들링, `ggplot`과 연계된 강한 차트 그리기, 야후를 기본으로 구글 및 각자 독자적인 데이터 소스로 부터 필요한 데이터를 손쉽게 가져오는 기능, 성능 분석 함수들을 제공하고 있습니다.

## 주가 지수 가져오기

`tidyquant`는 [야후 파이넨스](https://finance.yahoo.com)에서 정보를 가져옵니다. 가져오는 데이터 소스를 바꾸고 싶으면 어떤 곳에서 가져올지 결정할 수 있는데, `tq_get_options()`는 가능한 후보를 보여줍니다.

```{r}
if (!require(tidyquant)) install.packages("tidyquant", verbose = F)
library(tidyquant)
tq_get_options()
```

이때 코스피와 코스닥을 이르는 이름이 각각 `^KS11`와 `^KOSDAQ`입니다. 각각 한번 가져와 보겠습니다.

```{r}
tq_get("^KS11")
tq_get("^KOSDAQ")
```

각 기업의 주가를 가져오려면 종목 번호를 알고 있어야 합니다. 양식은 `종목 번호.KS`입니다. 종목번호는 세종기업 데이터에서 가져온 정보를 활용하겠습니다.

```{r}
url<-"https://github.com/mrchypark/sejongFinData/raw/master/codeData.csv"
download.file(url,destfile = "./codeData.csv")
codeData<-read.csv("./codeData.csv",stringsAsFactors = F)
head(codeData)
```

삼성전자를 가져와 볼까요.
```{r}
tar<-paste0(codeData[grep("^삼성전자$",codeData$`종목명`),1],".KS")
tq_get(tar)
```

날짜를 지정할 수도 있습니다.
```{r}
tq_get(tar, from="2016-01-01", to="2016-05-05")

```

배당금 정보는 `dividends` 에서 확인하시면 됩니다.
```{r}
tq_get(tar, get = "dividends")

```

`야후 파이넨스`가 데이터 소스이다 보니 모든 정보가 있다고 보기 어렵니다. 네이버 파이넨스에서 크롤링 하는 것이 방법이라고 생각합니다.

### Quandl

[Quandl](https://www.quandl.com/)은 방대한 양의 경제, 주식에 대한 정보를 가지고 서비스하는 데이터 판매 기업입니다. `Quandl`이라는 자체 패키지만을 사용해도 되고, `tidyquant`가 내장하고 있어서 같이 사용해도 됩니다.


## tidyverse와 함께 사용하는 시계열 데이터

그 동안의 주식관련 패키지들은 파이프 연산자 `%>%`와 함꼐 사용하지 못했는데, `tidyquant`는 그런 문제를 해결하였습니다. 아래 2가지 중요한 함수를 추가함으로써 `dplyr`과 `tidyr`의 함수와 함께 사용할 수 있게 되었습니다.


* `tq_transmute()`: 계산된 내용의 컬럼만으로 데이터를 구성합니다.
* `tq_mutate()`: 데이터에 계산된 내용의 컬럼을 추가합니다.

## `tq_`에서 계산 가능한 함수들

`tq_transmute_fun_options()` 함수는 각 참고 패키지에서 활용할 수 있는 함수의 리스트를 보여줍니다. 모두 `zoo`, `xts`, `quantmod`, `TTR`, `PerformanceAnalytics`의 5개 패키지내의 함수를 지원합니다.

```{r}
tq_transmute_fun_options() %>% str
```

### zoo 함수

```{r}
tq_transmute_fun_options()$zoo
```

* 롤링관련 함수 :
    * 롤링 마진에 기능을 적용하는 일반적인 기능.
    * form :`rollapply(data, width, FUN, ..., by = 1, by.column = TRUE, fill = if (na.pad) NA, na.pad = FALSE, partial = FALSE, align = c("center", "left", "right"), coredata = TRUE)`.
    * 옵션에는 `rollmax`,`rollmean`,`rollmedian`,`rollsum` 등이 있습니다.

### xts 함수

```{r}
tq_transmute_fun_options()$xts
```


* 기간 적용 기능 :
    * 기능을 시간 세그먼트 (예 : `max`, `min`, `mean` 등)에 적용합니다.
    * 양식 :`apply.daily (x, FUN, ...)`.
    * 옵션은`apply.daily`,`weekly`,`monthly`,`quarterly`,`yearly`를 포함합니다.

* 기간 기능 :
    * 시계열을 낮은 주기성의 시계열로 변환합니다 (예 : 매일 매일의 주기성으로 변환).
    * 형식 :`to.period (x, period = 'months', k = 1, indexAt, name = NULL, OHLC = TRUE, ...)`.
    * 옵션에는`to.minutes`,`hourly`,`daily`,`weekly`,`monthly`,`quarterly`,`yearly`가 포함됩니다.
    * __참고__ :`to.period`와`to.monthly` (`to.weekly`,`to.quarterly` 등) 양식의 리턴 구조는 다릅니다. `to.period`는 날짜를 반환하고, to.months는 MON YYYY 문자를 반환합니다. `lubridate`를 통해 시계열로 작업하고 싶다면`to.period`를 사용하는 것이 가장 좋습니다.

     
### quantmod 함수

```{r}
tq_transmute_fun_options()$quantmod
```


* 비율 변경 (Delt) 및 Lag 기능
    * Delt :`Delt (x1, x2 = NULL, k = 0, type = c ( "arithmetic", "log"))`
        * Delt의 변형 : ClCl, HiCl, LoCl, LoHi, OpCl, OpHi, OpLo, OpOp
        * 양식 :`Opcl (OHLC)`
    * Lag :`Lag(x, k = 1)`/ Next :`Next(x, k = 1)`(`dplyr :: lag`과`dplyr :: lead`도 사용할 수 있습니다)

* 기간 반환 함수 :
    * 매일, 매주, 매월, 분기 별 및 연간을 포함하는 다양한주기에 대한 산술 또는 로그 반환을 가져옵니다.
    * 형식 :`periodReturn (x, period = 'monthly', 부분 집합 = NULL, type = 'arithmetic', leading = TRUE, ...)`

* 시리즈 기능 :
    * 계열을 설명하는 반환 값. 옵션에는 증감, 가감 및 고저 설명이 포함됩니다.
    * 양식 :`seriesHi (x)`,`seriesIncr (x, thresh = 0, diff. = 1L)`,`seriesAccel (x)`

### TTR 함수

```{r}
tq_transmute_fun_options()$TTR
```

* 웰즈 와일더의 방향 운동 지수 :
    *`ADX (HLC, n = 14, maType, ...)`
* 볼린저 밴드 :
    * BBands (HLC, n = 20, maType, sd = 2, ...) : 볼린저 밴드
* 변화율 / 운동량 :
    *`ROC (x, n = 1, type = c ( "연속", "이산"), na.pad = TRUE)`: 변화율
    *`운동량 (x, n = 1, na.pad = TRUE)`: 운동량
* 이동 평균 (maType) :
    *`SMA (x, n = 10, ...)`: 단순 이동 평균
    *`EMA (x, n = 10, wilder = FALSE, ratio = NULL, ...)`: 지수 이동 평균
    * DEMA (x, n = 10, v = 1, wilder = FALSE, ratio = NULL)`: 이중 지수 이동 평균
    * WMA (x, n = 10, wts = 1 : n, ...)`: 가중 이동 평균
    * EVWMA (가격, 수량, n = 10, ...) : 탄성, 체중 이동 평균
    *`ZLEMA (x, n = 10, 비율 = NULL, ...)`: Zero Lag Exponential Moving Average
    *`VWAP (가격, 물량, n = 10, ...)`: 물량 가중 평균 가격
    * VMA (x, w, 비율 = 1, ...) : 가변 길이 이동 평균
    *`HMA (x, n = 20, ...)`: 선체 이동 평균
    *`ALMA (x, n = 9, offset = 0.85, sigma = 6, ...)`: Arnaud Legoux 이사 평균
* MACD Oscillator :
    MACD (x, nFast = 12, nSlow = 26, nSig = 9, maType, percent = TRUE, ...)
* 상대 강도 지수 :
    *`RSI (가격, n = 14, maType, ...)`
* runFun :
    *`runSum (x, n = 10, cumulative = FALSE)`: n- 기간 이동 윈도우에 대한 합계를 반환합니다.
    *`runMin (x, n = 10, cumulative = FALSE)`: n- 기간 이동 윈도우에 대한 최소값을 반환합니다.
    *`runMax (x, n = 10, cumulative = FALSE)`: n- 기간 이동 윈도우에 대해 최대 값을 반환합니다.
    *`runMean (x, n = 10, cumulative = FALSE)`: n-period 이동 윈도우를 의미합니다.
    *`runMedian (x, n = 10, non.unique = "mean", cumulative = FALSE)`: n-period 이동 윈도우에 대한 중앙값을 반환합니다.
    * `runCov (x, y, n = 10, use = "all.obs", sample = TRUE, 누적 = FALSE)`: n-period 이동 윈도우에 대한 공분산을 반환합니다.
    *`runCor (x, y, n = 10, use = "all.obs", sample = TRUE, 누적 = FALSE)`: n-period 이동 윈도우에 대한 상관 관계를 반환합니다.
    *`runVar (x, y = NULL, n = 10, 샘플 = TRUE, 누적 = FALSE)`: n- 기간 이동 윈도우에 대한 분산을 반환합니다.
    *`runSD (x, n = 10, 샘플 = TRUE, 누적 = FALSE)`: n- 기간 이동 윈도우에 대한 표준 편차를 반환합니다.
    `runMAD (x, n = 10, center = NULL, stat = "중간 값", 상수 = 1.4826, non.unique = "평균", cumulative = FALSE)`n 기간 이동에 대한 중간 / 평균 절대 편차를 반환합니다. 창문.
    *`wilderSum (x, n = 10)`: n- 기간 이동 윈도우에 대해 Welles Wilder 스타일 가중치 합계를 되 돌린다.
* Stochastic Oscillator / Stochastic Momentum Index :
    Stochastic Oscillator (HLC, nFastK = 14, nFastD = 3, nSlowD = 3, maType, bounded = TRUE, smooth = 1, ...)
    * SMI (HLC, n = 13, nFast = 2, nSlow = 25, nSig = 9, maType, bounded = TRUE, ...) : 확률 모멘텀 지수

### PerformanceAnalytics 함수

```{r}
tq_transmute_fun_options()$PerformanceAnalytics
```

*`Return.annualized` 및`Return.annualized.excess` : 기간 반환을 취하여 연간 수익으로 통합합니다.
*`Return.clean` : 반환 값에서 특이 값을 제거합니다.
*`Return.excess` : 무위험 이자율을 초과하는 수익률로 수익률에서 무위험 이자율을 제거합니다.
*`zerofill` : 'NA'값을 0으로 대체하는 데 사용됩니다.

## ggplot2와 연계된 차트 그리기

`ggplot2` 차트를 그리는데 `R`에서 가장 유명한 패키지 입니다. `gg`는 [Grammar of Graphics](http://www.springer.com/us/book/9780387245447)의 줄임말로 그림을 생성하는 것에 대한 규칙을 제안하고 있습니다. `tidyquant`는 `ggplot2`에 더해 아래와 같은 기능을 추가로 제공합니다.

* __차트 종류__ : 두 개의 차트 타입 시각화는`geom_barchart`와`geom_candlestick`을 사용하여 가능합니다.
* __이동 평균__ : 'geom_ma'를 사용하여 7 개의 이동 평균 시각화를 사용할 수 있습니다.
* __Bollinger Bands__ : Bollinger 밴드는 'geom_bbands'를 사용하여 시각화 할 수 있습니다. BBand 이동 평균은 이동 평균에서 사용할 수있는 7 가지 중 하나 일 수 있습니다.
* __날짜 범위 확대__ : 차트의 특정 영역을 확대 할 때 데이터 손실을 방지하는 두 가지`coord` 함수 (`coord_x_date` 및`coord_x_datetime`)를 사용할 수 있습니다. 이것은 이동 평균 및 Bollinger 밴드 기하학을 사용할 때 중요합니다.

### 살펴보기

`tq_get`를 이용해서 사용할 데이터를 가져옵니다. 내장 데이터인 `FANG`과 애플, 아마존을 예시로 사용하겠습니다.

```{r}
data("FANG") 

AAPL <- tq_get("AAPL", get = "stock.prices", from = "2015-09-01", to = "2016-12-31")
AMZN <- tq_get("AMZN", get = "stock.prices", from = "2000-01-01", to = "2016-12-31")
```

'end` 매개 변수는 예제 전체에서 날짜 제한을 설정할 때 사용됩니다.

```{r}
end <- as_date("2016-12-31")
```


## 차트 종류

* [Bar Chart](http://www.investopedia.com/terms/b/barchart.asp): `geom_barchart`을 사용합니다.
* [Candlestick Chart](http://www.investopedia.com/terms/c/candlestick.asp): `geom_candlestick`을 사용합니다.

### 라인 차트

`tidyquant`의 `geom_`함수를 사용하여 가로 막대형 차트와 촛대형 차트를 시각화하기 전에 단순한 선 차트로 주가를 시각화하여 `그래픽 문법`을 확인해보겠습니다. 이것은`ggplot2` 패키지의`geom_line`을 사용하여 이루어집니다. 주식 데이터로 시작하고 파이프 연산자 (`%> %`)를 사용하여`ggplot ()`함수로 보냅니다.

```{r}
AAPL %>%
    ggplot(aes(x = date, y = close)) +
    geom_line() +
    labs(title = "AAPL Line Chart", y = "Closing Price", x = "") + 
    theme_tq()
```


### 바 차트

바 차트는  `geom_line`를 `geom_barchart`로 바꾸는 걸로 해결됩니다. `aes()`내의 내용을 의미에 맞게 조정하는 것으로 바 차트를 그리는 것이 끝납니다.

```{r}
AAPL %>%
    ggplot(aes(x = date, y = close)) +
    geom_barchart(aes(open = open, high = high, low = low, close = close)) +
    labs(title = "AAPL Bar Chart", y = "Closing Price", x = "") + 
    theme_tq()
```

우리는`coord_x_date`를 사용하여 특정 섹션을 확대 / 축소합니다.이 섹션에는`xlim` 및`ylim` 인수가`c (start, end)`로 지정되어 차트의 특정 영역에 초점을 맞 춥니 다. `xlim`의 경우 우리는`lubridate`를 사용하여 문자 날짜를 날짜 클래스로 변환 한 다음`weeks ()`함수를 사용하여 6 주를 뺍니다. `ylim`의 경우 가격을 100에서 120까지 확대합니다.

```{r}
AAPL %>%
    ggplot(aes(x = date, y = close)) +
    geom_barchart(aes(open = open, high = high, low = low, close = close)) +
    labs(title = "AAPL Bar Chart", 
         subtitle = "Zoomed in using coord_x_date",
         y = "Closing Price", x = "") + 
    coord_x_date(xlim = c(end - weeks(6), end),
                 ylim = c(100, 120)) + 
    theme_tq()
```

색상은`color_up` 및`color_down` 인수를 사용하여 수정할 수 있으며`size`와 같은 매개 변수를 사용하여 모양을 제어 할 수 있습니다.

```{r}
AAPL %>%
    ggplot(aes(x = date, y = close)) +
    geom_barchart(aes(open = open, high = high, low = low, close = close),
                     color_up = "darkgreen", color_down = "darkred", size = 1) +
    labs(title = "AAPL Bar Chart", 
         subtitle = "Zoomed in, Experimenting with Formatting",
         y = "Closing Price", x = "") + 
    coord_x_date(xlim = c(end - weeks(6), end),
                 ylim = c(100, 120)) + 
    theme_tq()
```

### 캔들 차트

캔들 차트 또한 바 차트를 그리는 것과 거의 같습니다.

```{r}
AAPL %>%
    ggplot(aes(x = date, y = close)) +
    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +
    labs(title = "AAPL Candlestick Chart", y = "Closing Price", x = "") +
    theme_tq()
```

색상은`color_up`과`color_down`을 사용하여 선 색상을 조절할 수 있고, `fill_up`과`fill_down`은 사각형을 채 웁니다.

```{r}
AAPL %>%
    ggplot(aes(x = date, y = close)) +
    geom_candlestick(aes(open = open, high = high, low = low, close = close),
                        color_up = "darkgreen", color_down = "darkred", 
                        fill_up  = "darkgreen", fill_down  = "darkred") +
    labs(title = "AAPL Candlestick Chart", 
         subtitle = "Zoomed in, Experimenting with Formatting",
         y = "Closing Price", x = "") + 
    coord_x_date(xlim = c(end - weeks(6), end),
                 ylim = c(100, 120)) + 
    theme_tq()
```

<a class="anchor" id="mult-chart"></a>

### 여러개의 차트를 그리기

`facet_wrap`을 사용하여 동시에 여러 주식을 시각화 할 수 있습니다. `ggplot ()`의 `aes()`에`group`을 추가하고`ggplot` 워크 플로우의 끝에서`facet_wrap()`함수와 결합함으로써 네 개의 "FANG"주식을 동시에 모두 볼 수 있습니다.


```{r, fig.height=5}
start <- end - weeks(6)
FANG %>%
    filter(date >= start - days(2 * 15)) %>%
    ggplot(aes(x = date, y = close, group = symbol)) +
    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +
    labs(title = "FANG Candlestick Chart", 
         subtitle = "Experimenting with Mulitple Stocks",
         y = "Closing Price", x = "") + 
    coord_x_date(xlim = c(start, end)) +
    facet_wrap(~ symbol, ncol = 2, scale = "free_y") + 
    theme_tq()
```

## 트랜드 시각화

[Moving averages](http://www.investopedia.com/terms/m/movingaverage.asp) are critical to evaluating time-series trends. `tidyquant` includes geoms to enable "rapid prototyping" to quickly visualize signals using moving averages and Bollinger bands.


<a class="anchor" id="mavg"></a>

### 이동 평균

`tidyquant`에서는 다양한 이동평균 함수를 제공합니다.

* __[Simple moving averages (SMA)](http://www.investopedia.com/terms/s/sma.asp)__
* __[Exponential moving averages (EMA)](http://www.investopedia.com/terms/e/ema.asp)__
* __[Weighted moving averages (WMA)](http://www.investopedia.com/ask/answers/071414/whats-difference-between-moving-average-and-weighted-moving-average.asp)__
* __[Double exponential moving averages (DEMA)](http://www.investopedia.com/articles/trading/10/double-exponential-moving-average.asp)__
* __[Zero-lag exponential moving averages (ZLEMA)](https://en.wikipedia.org/wiki/Zero_lag_exponential_moving_average)__
* __[Volume-weighted moving averages (VWMA)](http://www.investopedia.com/articles/trading/11/trading-with-vwap-mvwap.asp)__ (also known as VWAP)
* __[Elastic, volume-weighted moving averages (EVWMA)](http://www.investopedia.com/articles/trading/11/trading-with-vwap-mvwap.asp)__ (also known as MVWAP)

이동 평균은`geom_ma` 함수로 차트에 추가 된 레이어로 적용됩니다. 기하 구조는`TTR` 패키지에서`SMA`,`EMA`,`WMA`,`DEMA`,`ZLEMA`,`VWMA`,`EVWMA`와 같은 기본 이동 평균 함수의 래퍼입니다.

### Example 1: 50일/200일 단순 이동 평균 차트 작성

```{r}
AAPL %>%
    ggplot(aes(x = date, y = close)) +
    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +
    geom_ma(ma_fun = SMA, n = 50, linetype = 5, size = 1.25) +
    geom_ma(ma_fun = SMA, n = 200, color = "red", size = 1.25) + 
    labs(title = "AAPL Candlestick Chart", 
         subtitle = "50 and 200-Day SMA", 
         y = "Closing Price", x = "") + 
    coord_x_date(xlim = c(end - weeks(24), end),
                 ylim = c(100, 120)) + 
    theme_tq()
```

### Example 2: 지수 이동 평균 차트

```{r}
AAPL %>%
    ggplot(aes(x = date, y = close)) +
    geom_barchart(aes(open = open, high = high, low = low, close = close)) +
    geom_ma(ma_fun = EMA, n = 50, wilder = TRUE, linetype = 5, size = 1.25) +
    geom_ma(ma_fun = EMA, n = 200, wilder = TRUE, color = "red", size = 1.25) + 
    labs(title = "AAPL Bar Chart", 
         subtitle = "50 and 200-Day EMA", 
         y = "Closing Price", x = "") + 
    coord_x_date(xlim = c(end - weeks(24), end),
                 ylim = c(100, 120)) +
    theme_tq()
```

## 볼린저 밴드

[Bollinger Bands] https://en.wikipedia.org/wiki/Bollinger_Bands)는 이동 평균(일반적으로 상하 2SD) 주위의 범위를 플로팅하여 변동성을 시각화하는 데 사용됩니다. 그것들은 이동 평균을 사용하기 때문에,`geom_bbands` 함수는`geom_ma`와 거의 동일하게 작동합니다. 동일한 7 개의 이동 평균이 호환됩니다. 가장 큰 차이점은 기본적으로 2 인 표준 편차 인`sd` 인수와 밴드를 계산하는 데 필요한 'high', 'low'및 'close'를 `aes()`에 추가하는 것입니다.

### Example 1: SMA를 사용하여 BBands 적용

간단한 이동 평균을 사용하여 Bollinger Bands를 추가하는 기본 예제를 살펴 보겠습니다.

```{r}
AAPL %>%
    ggplot(aes(x = date, y = close, open = open,
               high = high, low = low, close = close)) +
    geom_candlestick() +
    geom_bbands(ma_fun = SMA, sd = 2, n = 20) +
    labs(title = "AAPL Candlestick Chart", 
         subtitle = "BBands with SMA Applied", 
         y = "Closing Price", x = "") + 
    coord_x_date(xlim = c(end - weeks(24), end),
                 ylim = c(100, 120)) + 
    theme_tq()
```

### Example 2: Bollinger Bands의 모양 바꾸기

모양은`color_ma`,`color_bands`,`alpha`,`fill` 인자를 사용하여 수정할 수 있습니다. BBands에 새로운 서식을 적용한 Example 1과 같은 그림이 있습니다.

```{r}
AAPL %>%
    ggplot(aes(x = date, y = close, open = open,
               high = high, low = low, close = close)) +
    geom_candlestick() +
    geom_bbands(ma_fun = SMA, sd = 2, n = 20, 
                linetype = 4, size = 1, alpha = 0.2, 
                fill        = palette_light()[[1]], 
                color_bands = palette_light()[[1]], 
                color_ma    = palette_light()[[2]]) +
    labs(title = "AAPL Candlestick Chart", 
         subtitle = "BBands with SMA Applied, Experimenting with Formatting", 
         y = "Closing Price", x = "") + 
    coord_x_date(xlim = c(end - weeks(24), end),
                 ylim = c(100, 120)) + 
    theme_tq()
```


### Example 3: 여러 주식에 BBands 추가

```{r, fig.height=5}
start <- end - weeks(24)
FANG %>%
    filter(date >= start - days(2 * 20)) %>%
    ggplot(aes(x = date, y = close, 
               open = open, high = high, low = low, close = close, 
               group = symbol)) +
    geom_barchart() +
    geom_bbands(ma_fun = SMA, sd = 2, n = 20, linetype = 5) +
    labs(title = "FANG Bar Chart", 
         subtitle = "BBands with SMA Applied, Experimenting with Multiple Stocks", 
         y = "Closing Price", x = "") + 
    coord_x_date(xlim = c(start, end)) +
    facet_wrap(~ symbol, ncol = 2, scales = "free_y") + 
    theme_tq()
```


## ggplot2 함수

기본 `ggplot2`는 재무 데이터를 분석하는데 유용한 많은 기능을 가지고 있습니다. 아마존(AMZN)을 사용하여 몇 가지 간단한 예제를 살펴 보겠습니다.


### Example 1 : scale_y_log10을 사용한 로그 스케일

`ggplot2`는 y 축을 로그 스케일로 스케일하기위한`scale_y_log10 ()`함수를 가지고 있습니다. 이는 분석 할 수있는 선형 추세를 조정하는 경향이 있으므로 매우 유용합니다.

__Continuous Scale__:

```{r}
AMZN %>%
    ggplot(aes(x = date, y = adjusted)) +
    geom_line(color = palette_light()[[1]]) + 
    scale_y_continuous() +
    labs(title = "AMZN Line Chart", 
         subtitle = "Continuous Scale", 
         y = "Closing Price", x = "") + 
    theme_tq()
```

__Log Scale__:

```{r}
AMZN %>%
    ggplot(aes(x = date, y = adjusted)) +
    geom_line(color = palette_light()[[1]]) + 
    scale_y_log10() +
    labs(title = "AMZN Line Chart", 
         subtitle = "Log Scale", 
         y = "Closing Price", x = "") + 
    theme_tq()
```



### Example 2: geom_smooth로 회귀 추세선

우리는 워크 플로우에`geom_smooth ()`함수를 빠르게 추가하는 추세선을 적용 할 수 있습니다. 이 함수는 선형(`lm`)과 loess(`loess`) 를 포함한 몇 가지 예측 방법을 가지고 있습니다. 

__Linear__:

```{r}
AMZN %>%
    ggplot(aes(x = date, y = adjusted)) +
    geom_line(color = palette_light()[[1]]) + 
    scale_y_log10() +
    geom_smooth(method = "lm") +
    labs(title = "AMZN Line Chart", 
         subtitle = "Log Scale, Applying Linear Trendline", 
         y = "Adjusted Closing Price", x = "") + 
    theme_tq()
```

### Example 3: geom_segment로 차트 볼륨

우리는`geom_segment ()`함수를 사용하여 라인의 시작과 끝을 xy 점으로하는 일일 볼륨을 차트로 표시 할 수 있습니다. `aes()`를 사용하여 볼륨의 값을 기준으로 색상을 지정하여 이러한 데이터를 강조 표시합니다. 

```{r}
AMZN %>%
    ggplot(aes(x = date, y = volume)) +
    geom_segment(aes(xend = date, yend = 0, color = volume)) + 
    geom_smooth(method = "loess", se = FALSE) +
    labs(title = "AMZN Volume Chart", 
         subtitle = "Charting Daily Volume", 
         y = "Volume", x = "") +
    theme_tq() +
    theme(legend.position = "none") 
```

특정 지역을 확대 할 수 있습니다. `scale_color_gradient`를 사용하여 고점 및 저점을 빠르게 시각화 할 수 있으며`geom_smooth`를 사용하여 추세를 볼 수 있습니다.

```{r}
start <- end - weeks(24)
AMZN %>%
    filter(date >= start - days(50)) %>%
    ggplot(aes(x = date, y = volume)) +
    geom_segment(aes(xend = date, yend = 0, color = volume)) +
    geom_smooth(method = "loess", se = FALSE) +
    labs(title = "AMZN Bar Chart", 
         subtitle = "Charting Daily Volume, Zooming In", 
         y = "Volume", x = "") + 
    coord_x_date(xlim = c(start, end)) +
    scale_color_gradient(low = "red", high = "darkblue") +
    theme_tq() + 
    theme(legend.position = "none") 
```


## 테마

`tidyquant` 패키지는 3 가지 테마로 구성되어있어 신속하게 재무 차트를 조정 할 수 있습니다.

* __Light__: `theme_tq()` + `scale_color_tq()` + `scale_fill_tq()`
* __Dark__: `theme_tq_dark()` + `scale_color_tq(theme = "dark")` + `scale_fill_tq(theme = "dark")`
* __Green__: `theme_tq_green()` + `scale_color_tq(theme = "green")` + `scale_fill_tq(theme = "green")`

## Dark

```{r, fig.height = 6}
n_mavg <- 50 # Number of periods (days) for moving average
FANG %>%
    filter(date >= start - days(2 * n_mavg)) %>%
    ggplot(aes(x = date, y = close, color = symbol)) +
    geom_line(size = 1) +
    geom_ma(n = 15, color = "darkblue", size = 1) + 
    geom_ma(n = n_mavg, color = "red", size = 1) +
    labs(title = "Dark Theme",
         x = "", y = "Closing Price") +
    coord_x_date(xlim = c(start, end)) +
    facet_wrap(~ symbol, scales = "free_y") +
    theme_tq_dark() +
    scale_color_tq(theme = "dark") +
    scale_y_continuous(labels = scales::dollar)
```


# 웹 크롤링 기초 httr과 rvest

## 서버와 클라이언트

인터넷은 각각의 컴퓨터를 통신으로 연결하여 정보를 주고 받는 것입니다. 전화번호와 같은 `IP`라는 것이 있고, 번호를 외우는게 어려워서 `주소`라는 것을 만들어 관리합니다. `8.8.8.8`이 `IP`이고, `www.google.com`이 `주소`입니다. 뒤가 더 기억하기 쉽겠죠?

컴퓨터를 연결해서 자기 것처럼 사용하는 것을 `원격 연결`이라고 합니다. 그와 달리 인터넷의 웹페이지는 모두 제한된 텍스트 문서나 그림 같은 파일들만 확인할 있도록 구성되어 있습니다. 저런 문서와 그림을 가지고 있다가 약속된 요청을 하면 전송해주는 역할을 하것 것을 `서버`라고 하고, 문서와 그림을 규칙에 맞게 요청하고, 정해진대로 보여주는 역할을 하는 것을 `클라이언트`(`브라우저`)라고 합니다.

![](https://s3-ap-northeast-2.amazonaws.com/opentutorials-user-file/module/2790/5800.png)

## http/s 1.1

http/s는 이렇게 서버에 파일을 요청하는 방식을 미리 약속해 둔 것입니다. 요청의 종류는 다양하지만 크롤링에서 사용할 종류는 `GET`과 `POST`입니다. `GET`은 지정된 주소에 저장되어 있는 파일을 달라고 요청하는 것이고, `POST`는 내가 가지고 있는 데이터가 있는데 이걸 잘 바꿔서 결과를 돌려주세요 라고 하는 것입니다. 언어에서 `함수`와 비슷합니다.

* `GET`: 인터넷 주소를 기준으로 위치하고 있는 데이터나 파일을 달라고 요청하는 것.
* `POST`: `GET`과 같이 주소 위치에 요청하는데, 데이터를 같이 추가해서 요청하고, 결과를 받는 것.

위에 요청이라는 표현을 사용했는데, `request`와 `response`라는 개념이 있습니다. `http` 통신은 모두 `요청`을 해서 `응답`을 받는 구조 입니다. `GET`은 정상이라고 하는 코드와 몇몇 파일들, 이외에 쿠키, 해더 등을 `응답`으로 받습니다. `POST`는 `GET`과 같고, 계산 결과를 추가적으로 `응답`으로 보내기도 합니다.

위와 같은 `요청`을 하는 방식을 그대로 따라해서 정보를 받아오는 패키지가 `curl`, `httr`입니다. 이번에는 다루기 쉬운 `httr`을 사용해 보겠습니다.

## httr 패키지 소개

### 요청

`httr` 패키지는 `GET`요청을 할 있는 `GET()`함수가 있습니다.

```{r}
library(httr)
r <- GET("http://httpbin.org/get")
```

위에 요청으로 `r`이라는 응답 객체가 생깁니다. 응답 객체를 확인하면 사용된 실제 URL (모든 리디렉션 이후), http 상태, 파일 (내용) 유형, 크기 및 텍스트 파일 인 경우 처음 몇 줄의 출력과 같은 유용한 정보가 제공됩니다.

```{r}
r
```

다양한 헬퍼 메소드를 사용하여 응답의 중요한 부분을 추출하거나 객체로 직접 파고들 수 있습니다.

```{r}
status_code(r)
headers(r)
str(content(r))
```

이 소개에서`httpbin.org '를 사용할 것이다. 그것은 많은 종류의 http 요청을 받아 들여 그것이 수신 한 데이터를 설명하는 json을 반환합니다. 이렇게하면 httr이하는 일을 쉽게 볼 수 있습니다.


### 응답

서버에서 보낸 데이터는 상태 표시 줄, 헤더 및 본문의 세 부분으로 구성됩니다. 상태 표시 줄의 가장 중요한 부분은 http 상태 코드입니다. 요청이 성공했는지 여부를 알려줍니다. 해당 데이터에 액세스하는 방법, 본문 및 헤더에 액세스하는 방법을 보여 드리겠습니다.

#### 상태코드

상태 코드는 요청이 성공했는지 여부를 요약하는 3 자리 숫자입니다 (대화중인 서버에서 정의한대로). `http_status ()`를 사용하여 설명적인 메시지와 함께 상태 코드에 접근 할 수 있습니다.

```{r}
r <- GET("http://httpbin.org/get")
http_status(r)

r$status_code
```

요청이 성공하면 항상 `200`을 반환합니다. 일반적인 오류는 404(파일을 찾을 수 없음) 및 403 (사용 권한을 거부함)입니다. 웹 API와 대화하는 경우 일반 오류 코드 인 500이 표시 될 수 있습니다.  [http status cats](https://www.flickr.com/photos/girliemac/sets/72157628409467125)로 추가적인 내용을 확인하세요.

You can automatically throw a warning or raise an error if a request did not succeed.

```
warn_for_status(r)
stop_for_status(r)
```

#### body

`r`을 만들고 나면 객체로써 내용에 접근하는 방법이 필요합니다. `content()`는 응답 객체에서 `body`부분만 보여주는 함수로 옵션으로 `text`, `raw`, `parsed`가 있습니다.

`content(r, "text")` 는 내용을 모두 텍스트로 인지하고 보여줍니다.
```{r}
r <- GET("http://httpbin.org/get")
content(r, "text")
```

`httr`은 인코딩을 사용하여 서버의 콘텐츠를 자동으로 해독합니다.
`content-type`라는 정보가 http 헤더에 제공됩니다. 불행히도 항상 그런 것은 아닙니다.

```{r, eval = FALSE}
content(r, "text", encoding = "euc-kr")
```

올바른 인코딩이 무엇인지 알아내는 데 문제가있는 경우 `stringi :: stri_enc_detect (content (r, "raw"))`를 사용해볼 수 있습니다.

비 텍스트 요청의 경우(대부분 이미지) 원시 벡터로 요청 본문에 액세스 할 수 있습니다.

```{r}
content(r, "raw")
```

이것은 정확히 웹 서버가 보낸 바이트 순서이므로 그대로 저장하면 서버에서 받은 것과 정확히 같습니다.
```{r, eval = FALSE}
bin <- content(r, "raw")
writeBin(bin, "myfile.txt")
```

httr은 일반적인 파일 형식에 대한 여러 가지 기본 파서를 제공합니다.
```{r}
str(content(r, "parsed"))
```
    
## rvest 패키지 소개

`rvest`는 `html`문서에서 필요한 정보만 가져오기 위해 설계되었습니다. html 문서는 각 `node`의 성격을 정의하는 `tag`와 `id`, `class`를 가지고 있습니다. 이 세 가지로 정보가 필요한 `node`를 특정할 수 있고, `rvest`는 특정된 `nodes`의 정보를 가져올 다양한 방법을 제공합니다.

### chrome 개발자 도구

`chrome`은 구글이 만든 브라우저로 웹 페이지의 구조를 분석하는데 매우 유용한 기능들을 제공합니다. `windows`에서는 `F12`로 개발자 도구를 사용할 수 있습니다. `mac`은 `option(alt) + cmd + i`입니다.

여러 기능 중에 필요한 것은 `Elements`와 `Network`입니다.

웹 페이지에서 `node`의 정보가 필요한 요소를 마우스 우클릭을 하고 `검사`를 확인해보면 `Elements` 창이 열리면서 요소에 해당하는 `html`문서를 하이라이트해서 보여줍니다. 그곳 `node`의 `tag`, `id`, `class`를 확인하여 `rvest`로 특정 부분만 가져와 보겠습니다.

### imdb에서 배우 정보 가져오기

[imdb](http://www.imdb.com)는 해외 영화정보 사이트로 html로 구성되어 있어 크롤링 연습에 많이 사용하는 대표적인 곳입니다.

`rvest`를 사용해서 `설국열차`에 참석한 사람들의 정보를 가져와 보겠습니다.

```{r}
library(rvest)
html <- read_html("http://www.imdb.com/title/tt4481854/")
cast <- html_nodes(html, "#titleCast .itemprop")
html_text(cast)
```

`tag`와 `id`, `class`를 세세하게 지정하는 것이 자료를 처리하기 쉽게 가져오는 요령입니다.

```{r}
cast <- html_nodes(html, "#titleCast span.itemprop")
length(cast)

html_text(cast)
```

`tidyverse`의 파이프 연산자를 사용해서 가져오는 것이 더 가독성과 재사용성이 좋습니다.

```{r}

url <- "http://www.imdb.com/title/tt1490017/"

read_html(url) %>% 
  html_nodes("#titleCast span.itemprop") %>%
  html_text

```

# 형태소 분석기 KoNLP

한글 형태소 분석기인 `KoNLP`는 [한나눔 형태소 분석기](http://semanticweb.kaist.ac.kr/hannanum/)를 R에서 사용할 수 있게 작성한 패키지로 R에서 형태소 분석을 할 때 거의 유일한 선택지입니다. 덕분에 명사 추출등을 이용한 워드클라우드 샘플 코드가 공개되면서 많은 사람들이 다양한 워드 클라우드를 만들 수 있게 되었습니다. R에서는 [wordcloud](https://cran.r-project.org/web/packages/wordcloud/index.html)와 다양한 기능이 개선된 [wordcloud2](https://cran.r-project.org/web/packages/wordcloud2/vignettes/wordcloud.html)를 사용해서 쉽게 워드클라우드를 만들수 있습니다.

## 함수 설명

```{r}
library(KoNLP)

useSejongDic()
```

명사를 추출합니다.
```{r}
extractNoun("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
```

벡터를 입력으로 받을 수 있습니다. `sapply` 같은 함수를 함께 사용하지 않아도 됩니다.
```{r}
extractNoun(c("R은 free 소프트웨어이고, [완전하게 무보증]입니다.", 
                  "일정한 조건에 따르면, 자유롭게 이것을 재배포할수가 있습니다.")
                )
```

형태소 태깅을 2단계 수준으로 조정해서 할 수 있습니다.
```{r}
SimplePos09("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
SimplePos22("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
```

### 품사 태그(KAIST 방식)

![](https://t1.daumcdn.net/thumb/R1280x0/?fname=http://t1.daumcdn.net/brunch/service/user/275I/image/fGU_seGiDuYJR67aMRe16A8ykyU.jpg)

몇 가지 방식있는데, `KoNLP`는 `KAIST` 방식을 사용합니다. 엔진을 한나눔을 사용함으로써 종속적이 된 것으로 보입니다.

가능성 있는 모든 결과를 보여줍니다.
```{r}
MorphAnalyzer("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
```

자모 단위로 잘라서 보여줍니다.
```{r}
convertHangulStringToJamos("R는 많은 공헌자에의한 공동 프로젝트입니다")
```

키보드 매칭 기준으로 영타로 바꿔줍니다.
```{r}
convertHangulStringToKeyStrokes("R는 많은 공헌자에의한 공동 프로젝트입니다")
convertHangulStringToKeyStrokes("R는 많은 공헌자에의한 공동 프로젝트입니다", isFullwidth =F)

```

자모 단위로 잘라져 있는 결과를 다시 합칩니다.
```{r}
str <- convertHangulStringToJamos("배포 조건의 상세한것에 대해서는 'license()' 또는 'licence()' 라고 입력해주십시오")
(str2 <-paste(str, collapse=""))
HangulAutomata(str2)
```

최근 [NIADic](http://www.etnews.com/20170221000372)을 공개하는 것을 [KoNLP 제작자](http://freesearch.pe.kr/)에게 의뢰함으로써 사전의 공개가 R에서 우선적으로 이루어졌습니다. 기존 세종 사전의 9만 단어에서 약 98만 단어로 사전이 확보되어 성능의 개선을 기대할 수 있습니다.

```{r}
useSystemDic()
extractNoun("성긴털제비꽃은 너무 예쁘다.")
SimplePos09("성긴털제비꽃은 너무 예쁘다.")
SimplePos22("성긴털제비꽃은 너무 예쁘다.")
MorphAnalyzer("성긴털제비꽃은 너무 예쁘다.")

useSejongDic()
extractNoun("성긴털제비꽃은 너무 예쁘다.")
SimplePos09("성긴털제비꽃은 너무 예쁘다.")
SimplePos22("성긴털제비꽃은 너무 예쁘다.")
MorphAnalyzer("성긴털제비꽃은 너무 예쁘다.")

useNIADic()
extractNoun("성긴털제비꽃은 너무 예쁘다.")
SimplePos09("성긴털제비꽃은 너무 예쁘다.")
SimplePos22("성긴털제비꽃은 너무 예쁘다.")
MorphAnalyzer("성긴털제비꽃은 너무 예쁘다.")
```


## java 문제 해결

아래는 제작자가 작성한 `java` 설치에 관련된 문제 해결법을 첨부하였습니다.

`KoNLP`는 한글 처리에 대한 전문적인 지식이 없는 사회학, 경영, 경제학 등의 연구자들 그리고 일반인들이 R 기반으로 통계적 텍스트 분석을 수행하기 위한 편의를 제공하는데 목적을 두고 있다. 최대한 전문적인 경험이 필요없게 구성을 하고 있으나 몇가지 사용자들이 어려움을 겪는 공통적인 부분이 있다는 것을 이곳에 정리하여 시행착오를 출이고자 한다.  물론 이런 부분을 패키지에 넣으면 되지 않을까 생각하시는 분들이 있을 수 있으나 대부분 이곳에 언급하는 어려움들은 패키지 레벨에서 해결하기 어려운 환경적인 이슈와 엮여 있다는 것을 미리 언급해 둔다.  어떤 사용자분들은 이런 경험을 하나도 하지 못할 경우도 있고, 어떤 분들은 대부분 경험해 봤을 수 있는 이슈들이라 생각되는 것을 정리하고자 한다. 



### 윈도우 `rJava` loading error 

`R`만으로 한글에 대한 처리를 하는건 매우 어렵다. 텍스트 처리 관련 함수도 적고, 여러 인코딩 이슈도 발생한다. 무엇보다 처리 속도 이슈가 있는데, 이를 위해 `Java`와 `Scala` 언어를 기본 처리 언어로 사용하고 있다. 따라서 대부분의 `R`함수들은 `Java`와 `Scala` 기반의 함수를 호출하기 위한 Wrapper 역할을 수행한다. 따라서 KoNLP가 수행되기 위한 자바 환경이 구축되는 것은 정상적으로 KoNLP를 사용하기 위한 필수 조건이다. 그리고 KoNLP가 의존성을 가지고 있는 rJava 패키지는 R에서 존재하는 수많은 자바 기반의 패키지들을 구동하는데 매우 필수적으로 사용되는 패키지이다. 따라서 적절히 환경을 설정해 놓는다면 앞으로 R을 사용하는데 많은 도움이 될 것이다. 


rJava 로딩 에러는 대부분 윈도우 기반의 환경에서 발생한다. 가장 중요한 부분은 사용자가 설치한 R의 버전과 Java의 버전이 맞는지 확인하는 것이다. 


```{r}
Sys.getenv("R_ARCH")
```

위 명령어로 확인해보면 R이 32비트 기반인지 64비트 기반인지 출력된다. 만일 `/x64`로 출력되면 64비트의 R이 설치된 것이다. 따라서 자바의 경우도 설치된 R의 아키텍처에 맞게 설치가 되어야 되는데, rJava로 문제가 생기는 대부분 이 부분이 맞지 않아서 생기는 문제이다. 

자바 환경 설치는 [이곳](https://java.com/ko/download/)에서 자동으로 다운로드 가능하다. 여기서 다른 문제가 있는데, 바로 구동되는 시스템이 아닌 구동된 브라우저의 아키텍처에 따라 64비트 자바 혹은 32비트 자바가 자동으로 선택되어져 다운로드 된다는 것이다. 이 부분은 [여기](https://java.com/ko/download/faq/java_win64bit.xml)를 확인해보면 정확한 정보를 얻을 수 있을 것이다.  64비트 자바를 설치하기 위해서는 64비트 브라우저를 열어 설치 링크를 통해 설치해야 된다. 현재 자신의 시스템에 설치된 자바를 보고 싶다면 윈도우 제어판에서 `Java` 정보를 확인해 보는것도 도움이 될 것이다. 


### 맥에서 `rJava` 문제 

Mac + R + rJava의 조합은 맥에서 가장 어려운 조합으로 보여진다. 이는 맥에서 기본적으로 제공하고있는 Java 1.6이 시스템의 자바 설정에 강제하고 있는 부분이 있는 것으로 판단되고 이를 R에서 해결하는게 매우 까다로운 것으로 알려져 있기 때문이다. 맥에서의 문제만 아니면 필자는 벌써 Java 1.7 이나 1.8로 KoNLP를 바꾸었을 것이다. 지금껏 KoNLP에서 Java 1.6을 지원하는 가장 큰 원인은 맥에서의 문제 때문이다. 

# word2vec을 R에서 해보자

`word2vec`은 딥러닝의 일종으로 한글은 [한글 word2vec 테스트](http://w.elnn.kr/search/)에서 확인해 볼 있습니다.

word2vec의 필요성과 역사 등은 김홍배님의 훌륭한 [자료](https://www.slideshare.net/ssuser06e0c5/i-64267027)가 있어서 확인해보시면 좋을 것 같습니다. 정상근 박사님의 [자료](http://mlcenter.postech.ac.kr/files/attach/lectures/SKT_%EC%A0%95%EC%83%81%EA%B7%BC_%EB%B0%95%EC%82%AC.pdf)도 좋습니다.

## 알고리즘의 종류

빠른 성능으로 개선된 모델인 google의 [word2vec](https://github.com/mukul13/rword2vec)을 시작으로 Stanford에발 발표한 [Glove](https://cran.r-project.org/web/packages/text2vec/vignettes/glove.html), facebook이 발표한 [fastText](https://cran.r-project.org/web/packages/fastTextR/README.html) 등이 있습니다. 우리는 빠른 속도를 인정받고 있는 fastText를 함께 실행해 보겠습니다.

[dbpedia](http://wiki.dbpedia.org/)의 문서를 학습용 데이터로 사용합니다.

```{r}
fn <- "dbpedia_csv.tar.gz"

if ( !file.exists(fn) ) {
    download.file("https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz",
                  fn)
    untar(fn)
}
```

```

library("fastTextR")

train <- sample(sprintf("__label__%s", readLines("dbpedia_csv/train.csv", encoding = "UTF-8")))
head(train)

train <- normalize(train)
writeLines(train, con = "dbpedia.train")

test <- readLines("dbpedia_csv/test.csv", encoding = "UTF-8")
test <- normalize(test)
labels <- gsub("\\D", "", substr(test, 1, 4))
test <- substr(test, 5, max(nchar(test)))
head(test)
head(labels)
```

```
cntrl <- ft.control(word_vec_size = 10L, learning_rate = 0.1, max_len_ngram = 2L, 
                    min_count = 1L, nbuckets = 10000000L, epoch = 5L, nthreads = 20L)

model <- fasttext(input = "dbpedia.train", method = "supervised", control = cntrl)
save.fasttext(model, "dbpedia")
```

```
model <- read.fasttext( "dbpedia.bin" )
test.pred <- predict(model, test, k = 1L, prob = TRUE)
str(test.pred)
test.pred <- predict(model, test, k = 1L, prob = FALSE)
str(test.pred)

confusion_matrix <- table(labels, gsub("\\D", "", test.pred$label))
confusion_matrix

sum(diag(confusion_matrix)) / sum(confusion_matrix)

```

```
fn <- "enwik9.zip"
if ( !file.exists(fn) ) {
    url <- "http://mattmahoney.net/dc/enwik9.zip"
    download.file(url, fn)
    unzip(fn)
}

fn <- "rw.zip"
if ( !file.exists(fn) ) {
    url <- "http://stanford.edu/~lmthang/morphoNLM/rw.zip"
    download.file(url, fn)
    unzip(fn)
}
```

```
clean_wiki <- function(x) {
    stopifnot(is.character(x))
    x <- gsub("[[:cntrl:]]", " ", x)
    x <- gsub("<.*>", "", x, perl = TRUE)  ## remove xml tags
    x <- gsub("&amp", "&", x, perl = TRUE) ## decode URL encoded chars
    x <- gsub("&lt", "<", x, perl = TRUE)
    x <- gsub("&gt", ">", x, perl = TRUE)
    x <- gsub("<ref[^<]*<\\/ref>", "", x, perl = TRUE) ## remove references <ref...> ... </ref>
    x <- gsub("<[^>]*>", "", x, perl = TRUE)           ## remove xhtml tags
    x <- gsub("\\[http:[^] ]*", "[", x, perl = TRUE)   ## remove normal url, preserve visible text
    x <- gsub("\\|thumb", "", x, perl = TRUE) ## remove images links, preserve caption
    x <- gsub("\\|left", "", x, perl = TRUE)
    x <- gsub("\\|right", "", x, perl = TRUE)
    x <- gsub("\\|\\d+px", "", x, perl = TRUE)
    x <- gsub("\\[\\[image:[^\\[\\]]*\\|", "", x, perl = TRUE)
    x <- gsub("\\[\\[category:([^|\\]]*)[^]]*\\]\\]", "[[\\1]]", x, perl = TRUE) ## show categories without markup
    x <- gsub("\\[\\[[a-z\\-]*:[^\\]]*\\]\\]", "", x, perl = TRUE) ## remove links to other languages
    x <- gsub("\\[\\[[^\\|\\]]*\\|", "[[", x, perl = TRUE) ## remove wiki url, preserve visible text
    x <- gsub("\\{\\{[^\\}]*\\}\\}", "", x, perl = TRUE) ## remove {{icons}} and {tables}
    x <- gsub("\\{[^\\}]*\\}", "", x, perl = TRUE)
    x <- gsub("\\[", "", x, perl = TRUE) ## remove [ and ]
    x <- gsub("\\]", "", x, perl = TRUE)
    x <- gsub("&[^;]*;", " ", x, perl = TRUE) ## remove URL encoded chars

    # convert to lowercase letters and spaces, spell digits
    x <- tolower(x)
    x <- gsub("0", " zero ", x, perl = TRUE)
    x <- gsub("1", " one ", x, perl = TRUE)
    x <- gsub("2", " two ", x, perl = TRUE)
    x <- gsub("3", " three ", x, perl = TRUE)
    x <- gsub("4", " four ", x, perl = TRUE)
    x <- gsub("5", " five ", x, perl = TRUE)
    x <- gsub("6", " six ", x, perl = TRUE)
    x <- gsub("7", " seven ", x, perl = TRUE)
    x <- gsub("8", " eight ", x, perl = TRUE)
    x <- gsub("9", " nine ", x, perl = TRUE)

    x <- gsub("[[:punct:]]", " ", x)
    x
}

```

```
library(XML)
html <- htmlParse("enwik9", encoding = "UTF-8")
txt <- xpathSApply(html, "//text", xmlValue) 
txt <- grep("#redirect", txt, value = TRUE, ignore.case = TRUE, invert = TRUE)
txt <- clean_wiki_pearl(txt)
txt <- paste(txt, collapse = " ")
txt <- gsub("\\s+", " ", txt)
writeLines(txt, con = "fil9"

cntrl <- ft.control(learning_rate = 0.025, word_vec_size = 5, epoch = 1, 
                    nthreads = 10L)

model <- fasttext("fil9", "skipgram", cntrl)
model

save.fasttext(model, "fil9_skipgram_model")

model <- read.fasttext("fil9_skipgram_model.bin")

queries <- readLines("rw/rw.txt")
queries <- unlist(lapply(strsplit(queries, "\\t"), head, 2))
queries <- tolower(queries)

word_vectors <- get_words(model, queries)
```

[301]: https://courses.edx.org/courses/course-v1:Microsoft+DAT204x+1T2017/df2f6d24fa78436f999b42375cba9a9e/
[302]: https://www.datacamp.com/courses/free-introduction-to-r
[303]: http://www.r-tutor.com/r-introduction/basic-data-types
[304]: https://ko.wikipedia.org/wiki/%EC%B0%A8%EC%9B%90
[305]: http://m.blog.naver.com/libido1014/120113775017
[306]: https://ko.wikipedia.org/wiki/JSON
[307]: https://github.com/jeremystan/tidyjson

[401]: https://github.com/forkonlp/N2H4/blob/master/R/getContent.R
[402]: https://github.com/forkonlp/N2H4/wiki/%EC%82%AC%EC%9A%A9-%EC%98%88%EC%8B%9C
[403]: https://www.facebook.com/groups/krstudy/permalink/767170710123870/
[404]: https://nsaunders.wordpress.com/2010/08/20/a-brief-introduction-to-apply-in-r/

[601]: http://jinson.tistory.com/entry/%ED%95%9C%EA%B8%80%ED%99%94-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-3-%EA%B8%B0%EC%88%A0%EB%B6%80%EC%B1%84
[602]: https://brunch.co.kr/@mrchypark/1
[603]: http://vita.had.co.nz/papers/tidy-data.html
[604]: http://hadley.nz/
[605]: https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html
[606]: http://freesearch.pe.kr/archives/3942
[607]: http://www.hellodatascience.com/?p=287
[608]: http://www.theanalysisfactor.com/wide-and-long-data/
[609]: http://plyr.had.co.nz/
[610]: https://www.jstatsoft.org/article/view/v040i01
[611]: http://lumiamitie.github.io/r/dplyr-advanced-databases/
[612]: https://github.com/Rdatatable/data.table/wiki/Getting-started